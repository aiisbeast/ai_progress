{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "Q4nagfePKXLO",
      "metadata": {
        "id": "Q4nagfePKXLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3f80409-1021-4147-e641-e5893275f432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
      "metadata": {
        "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4429484-248e-4831-9b6f-eee3eeb51ae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.7.1\n",
            "numpy version: 1.25.2\n",
            "tiktoken version: 0.7.0\n",
            "torch version: 2.3.0+cu121\n",
            "tensorflow version: 2.15.0\n",
            "pandas version: 2.0.3\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\", # For OpenAI's pretrained weights\n",
        "        \"pandas\"      # Dataset loading\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
      "metadata": {
        "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d86772-5ac6-4869-dd38-b207967d2dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip(url, zip_path, extracted_path, data_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
      "metadata": {
        "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "a9d132f2-15cd-4d9d-a5f2-e6e2fe362079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "0         0  Go until jurong point, crazy.. Available only ...\n",
              "1         0                      Ok lar... Joking wif u oni...\n",
              "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3         0  U dun say so early hor... U c already then say...\n",
              "4         0  Nah I don't think he goes to usf, he lives aro...\n",
              "...     ...                                                ...\n",
              "5567      1  This is the 2nd time we have tried 2 contact u...\n",
              "5568      0               Will ü b going to esplanade fr home?\n",
              "5569      0  Pity, * was in mood for that. So...any other s...\n",
              "5570      0  The guy did some bitching but I acted like i'd...\n",
              "5571      0                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ffa0f3d-1940-48b5-a1b9-6acdf7ac119a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>0</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ffa0f3d-1940-48b5-a1b9-6acdf7ac119a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ffa0f3d-1940-48b5-a1b9-6acdf7ac119a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ffa0f3d-1940-48b5-a1b9-6acdf7ac119a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f689ff57-2344-4579-b307-6ce69a00a4d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f689ff57-2344-4579-b307-6ce69a00a4d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f689ff57-2344-4579-b307-6ce69a00a4d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_832a75ca-f54f-4e13-a2ee-36143bd28d4f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_832a75ca-f54f-4e13-a2ee-36143bd28d4f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df[\"Label\"] = df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
      "metadata": {
        "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d51aa1-4819-4b0a-88dc-0eda3c3e7a44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "7be4a0a2-9704-4a96-b38f-240339818688",
      "metadata": {
        "id": "7be4a0a2-9704-4a96-b38f-240339818688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec38017-845f-4267-ce17-2a3d9817b435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham' instances to match the number of 'spam' instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
      "metadata": {
        "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
      },
      "outputs": [],
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "db3GmvoxhbC6",
      "metadata": {
        "id": "db3GmvoxhbC6"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/ScamDataNew.csv')\n",
        "testData=pd.read_excel(\"/content/scams13.xlsx\")\n",
        "df.rename(columns={'Text':'Scammer'},inplace=True)\n",
        "testData.rename(columns={'content': 'Scammer'}, inplace=True)\n",
        "testData.rename(columns={'is scam': 'Label'}, inplace=True)\n",
        "balanced_df= pd.concat([balanced_df, data], ignore_index=True)\n",
        "balanced_df= pd.concat([balanced_df, testData], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "KcY1_mTWyMpd",
      "metadata": {
        "id": "KcY1_mTWyMpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31129fa-19d8-4d7a-9dbc-02c01e459ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label Text                                            Scammer scam type  \\\n",
            "0         1  NaN  Hello this is HUGIE Finance calling.  We're cu...       NaN   \n",
            "1         0  NaN  Pepperfry item (Yukashi 3 Door Wardro...) deli...       NaN   \n",
            "2         1  NaN  Act now to benefit from our unique offer. Tran...       NaN   \n",
            "3         0  NaN  It's Shoppers Stop BirthYAY & we loved every m...       NaN   \n",
            "4         1  NaN  Hello I'm calling from MUTHOOT Finance.  We're...       NaN   \n",
            "...     ...  ...                                                ...       ...   \n",
            "1842      0  NaN  EXCITING NEWS! Dwayne 'The Rock' Johnson here!...  Phishing   \n",
            "1843      1  NaN  URGENT! Dwayne 'The Rock' Johnson here! I'm gi...  Phishing   \n",
            "1844      0  NaN  Hey! Dwayne 'The Rock' Johnson here! To celebr...  Phishing   \n",
            "1845      1  NaN  URGENT! Dwayne 'The Rock' Johnson here! I've p...  Phishing   \n",
            "1846      0  NaN  EXCITING NEWS! Dwayne 'The Rock' Johnson here!...  Phishing   \n",
            "\n",
            "                                       trick type  \\\n",
            "0                                             NaN   \n",
            "1                                             NaN   \n",
            "2                                             NaN   \n",
            "3                                             NaN   \n",
            "4                                             NaN   \n",
            "...                                           ...   \n",
            "1842  Scarcity, Using Fake Celebrity Endorsements   \n",
            "1843  Scarcity, Using Fake Celebrity Endorsements   \n",
            "1844  Scarcity, Using Fake Celebrity Endorsements   \n",
            "1845  Scarcity, Using Fake Celebrity Endorsements   \n",
            "1846  Scarcity, Using Fake Celebrity Endorsements   \n",
            "\n",
            "                                          attack type  \\\n",
            "0                                                 NaN   \n",
            "1                                                 NaN   \n",
            "2                                                 NaN   \n",
            "3                                                 NaN   \n",
            "4                                                 NaN   \n",
            "...                                               ...   \n",
            "1842                    Intentional spelling mistakes   \n",
            "1843                                 Homograph Attack   \n",
            "1844                                 Homograph Attack   \n",
            "1845  Intentional spelling mistakes, Homograph Attack   \n",
            "1846  Intentional spelling mistakes, Homograph Attack   \n",
            "\n",
            "                                                 reason  \n",
            "0                                                   NaN  \n",
            "1                                                   NaN  \n",
            "2                                                   NaN  \n",
            "3                                                   NaN  \n",
            "4                                                   NaN  \n",
            "...                                                 ...  \n",
            "1842  [\"It's a charity event, not a free giveaway\", ...  \n",
            "1843  [\"Creates a sense of urgency with 'URGENT!' to...  \n",
            "1844  [\"The message does not create a sense of urgen...  \n",
            "1845  ['Uses fake celebrity endorsement to build tru...  \n",
            "1846  [\"It's a legitimate charity campaign\", 'The li...  \n",
            "\n",
            "[1847 rows x 7 columns]\n"
          ]
        }
      ],
      "source": [
        "print(balanced_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "uQl0Psdmx15D",
      "metadata": {
        "id": "uQl0Psdmx15D"
      },
      "outputs": [],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "wDcwnHwuX_Q4",
      "metadata": {
        "id": "wDcwnHwuX_Q4"
      },
      "outputs": [],
      "source": [
        "# train_df.rename(columns={'Text': 'Scammer'}, inplace=True)\n",
        "# validation_df.rename(columns={'Text': 'Scammer'}, inplace=True)\n",
        "# test_df.rename(columns={'Text': 'Scammer'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "G-W_Ao0-Zebi",
      "metadata": {
        "id": "G-W_Ao0-Zebi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "d835afac-d3fa-4645-fac5-42eea1cafac2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label Text                                            Scammer scam type  \\\n",
              "0         0  NaN  Automatic payment of Rs.3000 will be deducted ...       NaN   \n",
              "1         1  NaN  Hi there, I'm reaching out from HDFC's custome...       NaN   \n",
              "2         1  NaN  Urgent! Your PayPa1 account has been temporarl...  Phishing   \n",
              "3         0  NaN  Nitesh, 3 days for our Merry Xmas Party with P...       NaN   \n",
              "4         1  NaN  Hello, I've been trying to send the amount for...       NaN   \n",
              "...     ...  ...                                                ...       ...   \n",
              "1287      0  NaN  Alert: We've detected unusual activity on your...  Phishing   \n",
              "1288      1  NaN  Dear Valued Customer, This is Officier John fr...  Phishing   \n",
              "1289      0  NaN  FLAT 50% OFF on purchase of 25K at the Benetto...       NaN   \n",
              "1290      1  NaN  Good day Sir. With our FAMILYSAFE plan your fa...       NaN   \n",
              "1291      0  NaN  URGENT: We've detected unusual activity on you...  Phishing   \n",
              "\n",
              "                                      trick type  \\\n",
              "0                                            NaN   \n",
              "1                                            NaN   \n",
              "2          Scarcity, Using Manipulative Language   \n",
              "3                                            NaN   \n",
              "4                                            NaN   \n",
              "...                                          ...   \n",
              "1287             Authority, Making False Threats   \n",
              "1288  Scarcity, Using Fake Accents or Identities   \n",
              "1289                                         NaN   \n",
              "1290                                         NaN   \n",
              "1291      Scarcity, Using Misleading Information   \n",
              "\n",
              "                                          attack type  \\\n",
              "0                                                 NaN   \n",
              "1                                                 NaN   \n",
              "2     Intentional spelling mistakes, Homograph Attack   \n",
              "3                                                 NaN   \n",
              "4                                                 NaN   \n",
              "...                                               ...   \n",
              "1287  Intentional spelling mistakes, Homograph Attack   \n",
              "1288  Intentional spelling mistakes, Homograph Attack   \n",
              "1289                                              NaN   \n",
              "1290                                              NaN   \n",
              "1291                    Intentional spelling mistakes   \n",
              "\n",
              "                                                 reason  \n",
              "0                                                   NaN  \n",
              "1                                                   NaN  \n",
              "2     [\"Creates a sense of urgency with 'Urgent!' to...  \n",
              "3                                                   NaN  \n",
              "4                                                   NaN  \n",
              "...                                                 ...  \n",
              "1287  [\"It's from a trusted source (the account prov...  \n",
              "1288  ['Uses scarcity tactic to create a sense of ur...  \n",
              "1289                                                NaN  \n",
              "1290                                                NaN  \n",
              "1291  ['It does not ask for sensitive information', ...  \n",
              "\n",
              "[1292 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd053f1a-0126-4fec-931f-34f615ca1d42\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "      <th>Scammer</th>\n",
              "      <th>scam type</th>\n",
              "      <th>trick type</th>\n",
              "      <th>attack type</th>\n",
              "      <th>reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Automatic payment of Rs.3000 will be deducted ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hi there, I'm reaching out from HDFC's custome...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Urgent! Your PayPa1 account has been temporarl...</td>\n",
              "      <td>Phishing</td>\n",
              "      <td>Scarcity, Using Manipulative Language</td>\n",
              "      <td>Intentional spelling mistakes, Homograph Attack</td>\n",
              "      <td>[\"Creates a sense of urgency with 'Urgent!' to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Nitesh, 3 days for our Merry Xmas Party with P...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Hello, I've been trying to send the amount for...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1287</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Alert: We've detected unusual activity on your...</td>\n",
              "      <td>Phishing</td>\n",
              "      <td>Authority, Making False Threats</td>\n",
              "      <td>Intentional spelling mistakes, Homograph Attack</td>\n",
              "      <td>[\"It's from a trusted source (the account prov...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1288</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Dear Valued Customer, This is Officier John fr...</td>\n",
              "      <td>Phishing</td>\n",
              "      <td>Scarcity, Using Fake Accents or Identities</td>\n",
              "      <td>Intentional spelling mistakes, Homograph Attack</td>\n",
              "      <td>['Uses scarcity tactic to create a sense of ur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>FLAT 50% OFF on purchase of 25K at the Benetto...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Good day Sir. With our FAMILYSAFE plan your fa...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1291</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>URGENT: We've detected unusual activity on you...</td>\n",
              "      <td>Phishing</td>\n",
              "      <td>Scarcity, Using Misleading Information</td>\n",
              "      <td>Intentional spelling mistakes</td>\n",
              "      <td>['It does not ask for sensitive information', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1292 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd053f1a-0126-4fec-931f-34f615ca1d42')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd053f1a-0126-4fec-931f-34f615ca1d42 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd053f1a-0126-4fec-931f-34f615ca1d42');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cfcdb7a3-5df8-450f-b9b0-e0cdf44bd798\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cfcdb7a3-5df8-450f-b9b0-e0cdf44bd798')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cfcdb7a3-5df8-450f-b9b0-e0cdf44bd798 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_21f23721-ce37-4e68-82b3-7f5ecc432c8e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_21f23721-ce37-4e68-82b3-7f5ecc432c8e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
      "metadata": {
        "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd30c847-efae-4b51-c50d-d6733462d008"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0ff0f6b2-376b-4740-8858-55b60784be73",
      "metadata": {
        "id": "0ff0f6b2-376b-4740-8858-55b60784be73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b87c796-8ccc-412e-acfe-800310bd17ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[42, 13, 314, 481, 1908, 340, 757]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "tokenizer.encode(\"K. I will sent it again\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
      "metadata": {
        "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Scammer\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        # Assuming label is a string, convert it to an integer before creating the tensor\n",
        "        label = int(self.data.iloc[index][\"Label\"])\n",
        "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "zE4J0x-CUjZr",
      "metadata": {
        "id": "zE4J0x-CUjZr"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Load the ScamData.csv file\n",
        "\n",
        "\n",
        "# # Split the data into train and test sets (80% train, 20% test)\n",
        "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Further split the train data into train and validation sets (80% train, 20% validation)\n",
        "# train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Save the split data into separate CSV files\n",
        "# train_data.to_csv('train1.csv', index=False)\n",
        "# test_data.to_csv('test1.csv', index=False)\n",
        "# validation_data.to_csv('validation1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "4EVDgw7-Zq_Q",
      "metadata": {
        "id": "4EVDgw7-Zq_Q"
      },
      "outputs": [],
      "source": [
        "# merged_df = pd.concat([train_data, train_df], ignore_index=True)\n",
        "# merged_df=pd.concat([merged_df,test])\n",
        "# merged_df.to_csv('train2.csv',index=False)\n",
        "# merged_df1 = pd.concat([test_data, test_df], ignore_index=True)\n",
        "# merged_df1.to_csv('test2.csv',index=False)\n",
        "# merged_df2 = pd.concat([validation_data, validation_df], ignore_index=True)\n",
        "# merged_df2.to_csv('validation2.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "uzj85f8ou82h",
      "metadata": {
        "id": "uzj85f8ou82h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5704c1-2b57-4116-d224-91856c339b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.SpamDataset object at 0x7f9b1b6d9e70>\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
      "metadata": {
        "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
      },
      "outputs": [],
      "source": [
        "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
      "metadata": {
        "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
      "metadata": {
        "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d50bea3b-78db-49b7-eaf1-881509aabe1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f9b1b6dbfd0>\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 155])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(train_loader)\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "    print(\"Input batch dimensions:\", input_batch.shape)\n",
        "    print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hu0OyC7Vu4vZ",
      "metadata": {
        "id": "Hu0OyC7Vu4vZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "IZfw-TYD2zTj",
      "metadata": {
        "id": "IZfw-TYD2zTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b61a7e7-645f-412a-8519-1f36d66abb5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "161 training batches\n",
            "23 validation batches\n",
            "47 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
      "metadata": {
        "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # Vocabulary size\n",
        "    \"context_length\": 1024,  # Context length\n",
        "    \"drop_rate\": 0.0,        # Dropout rate\n",
        "    \"qkv_bias\": True         # Query-key-value bias\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "022a649a-44f5-466c-8a8e-326c063384f5",
      "metadata": {
        "id": "022a649a-44f5-466c-8a8e-326c063384f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4550912-0097-4ec0-ac60-c20bd17a7364"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 82.4kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:00<00:00, 2.41MiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 23.3kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [00:16<00:00, 30.7MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 10.6MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:00<00:00, 1.76MiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:00<00:00, 1.78MiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from utils import GPTModel, load_weights_into_gpt\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
      "metadata": {
        "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71d888a-e00a-4d9c-acab-cbbc5e9a6cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "from utils import (\n",
        "    generate_text_simple,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
      "metadata": {
        "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ce40dcc-fa06-4d57-e6c5-896073694532"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' Answer with 'yes' or 'no'. Answer with 'yes' or 'no'. Answer with 'yes' or 'no'. Answer with 'yes'\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        "    \" Answer with 'yes' or 'no'.\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
      "metadata": {
        "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe92ff21-1867-400d-93a3-0b3934d53dac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fkMWFl-0etea",
      "metadata": {
        "id": "fkMWFl-0etea"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
      "metadata": {
        "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
      "metadata": {
        "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
      },
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
      "metadata": {
        "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a757523d-8c5f-4de9-d1ff-5b2d7e2cfa5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
      "metadata": {
        "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59c8d2b6-2ae4-4425-a304-d54404c30e7c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "Outputs dimensions: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs.shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
      "metadata": {
        "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26a516f-4248-40e8-cbab-94dc7315838b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
      "metadata": {
        "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
      "metadata": {
        "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
      },
      "outputs": [],
      "source": [
        "# Same as in chapter 5\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
      "metadata": {
        "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcedcea6-b068-41b6-e1e8-91ebd3b544b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 3.073\n",
            "Validation loss: 3.081\n",
            "Test loss: 2.835\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "64ce5b12-84cd-488c-8ea7-4cef5b2d947e",
      "metadata": {
        "id": "64ce5b12-84cd-488c-8ea7-4cef5b2d947e"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad() # Disable gradient tracking for efficiency\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "            logits = model(input_batch)[:, -1, :]  # Logits of last output token\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "2160418f-988b-40f3-bce8-e431021e97dc",
      "metadata": {
        "id": "2160418f-988b-40f3-bce8-e431021e97dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0be4bd7-1e75-42a6-e7e5-a401a0ba035e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 40.00%\n",
            "Validation accuracy: 41.25%\n",
            "Test accuracy: 38.75%\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "Csbr60to50FL",
      "metadata": {
        "id": "Csbr60to50FL"
      },
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous epoch\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
      "metadata": {
        "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
      },
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "X7kU3aAj7vTJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7kU3aAj7vTJ",
        "outputId": "b1bda5a9-f42d-4409-bfc9-5f065339309c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 3.081, Val loss 2.850\n",
            "Ep 1 (Step 000050): Train loss 0.691, Val loss 0.701\n",
            "Ep 1 (Step 000100): Train loss 0.667, Val loss 0.698\n",
            "Ep 1 (Step 000150): Train loss 0.627, Val loss 0.697\n",
            "Training accuracy: 52.50% | Validation accuracy: 52.50%\n",
            "Ep 2 (Step 000200): Train loss 0.674, Val loss 0.704\n",
            "Ep 2 (Step 000250): Train loss 0.602, Val loss 0.613\n",
            "Ep 2 (Step 000300): Train loss 0.399, Val loss 0.444\n",
            "Training accuracy: 80.00% | Validation accuracy: 95.00%\n",
            "Ep 3 (Step 000350): Train loss 0.411, Val loss 0.377\n",
            "Ep 3 (Step 000400): Train loss 0.323, Val loss 0.345\n",
            "Ep 3 (Step 000450): Train loss 0.341, Val loss 0.283\n",
            "Training accuracy: 80.00% | Validation accuracy: 80.00%\n",
            "Ep 4 (Step 000500): Train loss 0.304, Val loss 0.244\n",
            "Ep 4 (Step 000550): Train loss 0.131, Val loss 0.238\n",
            "Ep 4 (Step 000600): Train loss 0.201, Val loss 0.215\n",
            "Training accuracy: 90.00% | Validation accuracy: 97.50%\n",
            "Ep 5 (Step 000650): Train loss 0.208, Val loss 0.243\n",
            "Ep 5 (Step 000700): Train loss 0.138, Val loss 0.248\n",
            "Ep 5 (Step 000750): Train loss 0.224, Val loss 0.209\n",
            "Ep 5 (Step 000800): Train loss 0.173, Val loss 0.208\n",
            "Training accuracy: 97.50% | Validation accuracy: 95.00%\n",
            "Training completed in 1.52 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "cURgnDqdCeka",
      "metadata": {
        "id": "cURgnDqdCeka"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "OIqRt466DiGk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "OIqRt466DiGk",
        "outputId": "f1eac1b8-fcbf-40f0-d6f9-cb2cb59ef4fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "UHWaJFrjY0zW",
      "metadata": {
        "id": "UHWaJFrjY0zW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f2c284-371c-4689-a8ae-7983edf89bc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 94.64%\n",
            "Validation accuracy: 95.11%\n",
            "Test accuracy: 92.99%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "aHdn6xvL-IW5",
      "metadata": {
        "id": "aHdn6xvL-IW5"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[1]\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"Positive\" if predicted_label == 1 else \"Negative\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "apU_pf51AWSV",
      "metadata": {
        "id": "apU_pf51AWSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf270efd-6ec0-4392-d264-01e29601fc35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "1g5VTOo_Ajs5",
      "metadata": {
        "id": "1g5VTOo_Ajs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "407e91c9-ba38-4f17-b6b8-c0d07aba37fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Click this link to enter your account details to claim the lottery www.google.com\"\n",
        ")\n",
        "\n",
        "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "mYnX-gI1CfQY",
      "metadata": {
        "id": "mYnX-gI1CfQY"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"spam_classifier.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "vEJNK0piom2s",
      "metadata": {
        "id": "vEJNK0piom2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
      "metadata": {
        "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc045f05-3a09-4103-d693-2c1f11c7c8c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "model_state_dict = torch.load(\"spam_classifier.pth\")\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "6BzS-WMsK9GL",
      "metadata": {
        "id": "6BzS-WMsK9GL"
      },
      "outputs": [],
      "source": [
        "t1=pd.read_excel('/content/scams12.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "5M36i3R8Nl0X",
      "metadata": {
        "id": "5M36i3R8Nl0X"
      },
      "outputs": [],
      "source": [
        "text=t1['content']\n",
        "label=t1['is scam']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "WYDhDPDkOC8d",
      "metadata": {
        "id": "WYDhDPDkOC8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "DVhM3V7TNi3X",
      "metadata": {
        "id": "DVhM3V7TNi3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70bd6dca-90d0-425a-e02c-eaee9b7f004d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "0.6825095057034221\n"
          ]
        }
      ],
      "source": [
        "c=0\n",
        "c1=0\n",
        "for i in range(len(t1)):\n",
        "  st=classify_review(text[i], model, tokenizer, device, max_length=train_dataset.max_length)\n",
        "  pr='Negative' if label[i]==0 else'Positive'\n",
        "  print(st,pr)\n",
        "  if st=='Negative':\n",
        "    c1=c1+1\n",
        "  if st==pr:\n",
        "    c=c+1\n",
        "print(c/len(t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "lXgrM-8WOKJa",
      "metadata": {
        "id": "lXgrM-8WOKJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb2223a9-0be2-4f7a-8999-7f888a2e4d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "306\n"
          ]
        }
      ],
      "source": [
        "print(c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "NfD96hUNoam_",
      "metadata": {
        "id": "NfD96hUNoam_"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "QJREnDeMX1fi",
      "metadata": {
        "id": "QJREnDeMX1fi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621b82e8-6d7f-481f-a605-e5e354b354a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n"
          ]
        }
      ],
      "source": [
        "pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "3nwpIrtZSTr5",
      "metadata": {
        "id": "3nwpIrtZSTr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16c696f-ec30-4bbe-dcb5-c6c91b5e7eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:119: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
            "  torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from tokenizers import Encoding\n",
        "\n",
        "# Load fine-tuned GPT-2 model\n",
        "model_path = \"/content/spam_classifier.pth\"\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "# Prepare sample input\n",
        "dummy_input = torch.randint(0, 50257, (1, BASE_CONFIG[\"context_length\"]), dtype=torch.int64).to(device)\n",
        "torch.onnx.export(model, dummy_input, \"quantized_modelgpt.onnx\", opset_version=12, verbose=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "ebRJXygLW88e",
      "metadata": {
        "id": "ebRJXygLW88e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52e37ff-e621-42f2-96ca-4316ff869290"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of the ONNX file: 503057794 bytes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Path to your ONNX file\n",
        "onnx_file_path = \"quantized_modelgpt.onnx\"  # Replace with the path to your ONNX file\n",
        "\n",
        "# Get the size of the ONNX file\n",
        "onnx_file_size = os.path.getsize(onnx_file_path)\n",
        "\n",
        "print(\"Size of the ONNX file:\", onnx_file_size, \"bytes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "J0BNSn2uYKgq",
      "metadata": {
        "id": "J0BNSn2uYKgq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3be796c-4088-4d07-a1fd-ef8eaff8a597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx-tf\n",
            "  Downloading onnx_tf-1.10.0-py3-none-any.whl (226 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/226.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m174.1/226.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.1/226.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: onnx>=1.10.2 in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (1.16.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from onnx-tf) (6.0.1)\n",
            "Collecting tensorflow-addons (from onnx-tf)\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.10.2->onnx-tf) (3.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons->onnx-tf) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons->onnx-tf)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons, onnx-tf\n",
            "Successfully installed onnx-tf-1.10.0 tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
            "\n",
            "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
            "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
            "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
            "\n",
            "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
            "\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx-tf\n",
        "import onnx_tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "# onnx_model_path= onnx.load(\"quantized_modelgpt.onnx\")\n",
        "onnx_model = onnx.load('/content/quantized_modelgpt.onnx')\n",
        "# Define a mapping from old names to new names\n",
        "name_map = {\"input.1\": \"input_1\"}\n",
        "\n",
        "# Initialize a list to hold the new inputs\n",
        "new_inputs = []\n",
        "\n",
        "# Iterate over the inputs and change their names if needed\n",
        "for inp in onnx_model.graph.input:\n",
        "    if inp.name in name_map:\n",
        "        # Create a new ValueInfoProto with the new name\n",
        "        new_inp = onnx.helper.make_tensor_value_info(name_map[inp.name],\n",
        "                                                inp.type.tensor_type.elem_type,\n",
        "                                                [dim.dim_value for dim in inp.type.tensor_type.shape.dim])\n",
        "        new_inputs.append(new_inp)\n",
        "    else:\n",
        "        new_inputs.append(inp)\n",
        "\n",
        "# Clear the old inputs and add the new ones\n",
        "onnx_model.graph.ClearField(\"input\")\n",
        "onnx_model.graph.input.extend(new_inputs)\n",
        "\n",
        "# Go through all nodes in the model and replace the old input name with the new one\n",
        "for node in onnx_model.graph.node:\n",
        "    for i, input_name in enumerate(node.input):\n",
        "        if input_name in name_map:\n",
        "            node.input[i] = name_map[input_name]\n",
        "\n",
        "# Save the renamed ONNX model\n",
        "onnx.save(onnx_model, 'modelgpt2.onnx')"
      ],
      "metadata": {
        "id": "RkKDUWoxl7Em"
      },
      "id": "RkKDUWoxl7Em",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = onnx.load(\"modelgpt2.onnx\")\n",
        "# Convert ONNX model to TensorFlow format\n",
        "tf_model = onnx_tf.backend.prepare(onnx_model)"
      ],
      "metadata": {
        "id": "gz-V-aqsk2Ha"
      },
      "id": "gz-V-aqsk2Ha",
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_model.export_graph(\"modelgpt.tf\")"
      ],
      "metadata": {
        "id": "aNYJG8Vhk_ON"
      },
      "id": "aNYJG8Vhk_ON",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(\"modelgpt.tf\")\n",
        "tflite_model = converter.convert()\n",
        "open('modelgpt.tflite', 'wb').write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsmKdnSklYX9",
        "outputId": "38b4ff9c-a588-4daa-ee74-7120818f3de1"
      },
      "id": "xsmKdnSklYX9",
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "612195428"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.path.getsize('/content/modelgpt.tflite')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12SmFnwEmqt2",
        "outputId": "bc420dc6-dbfa-4c8e-d416-d53ab477ab94"
      },
      "id": "12SmFnwEmqt2",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "612195428"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load the TFLite model and allocate tensors.\n",
        "interpreter = tf.lite.Interpreter(model_path=\"modelgpt.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "def classify_text2(text, tokenizer, max_length, pad_token_id=50256):\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = input_details[0]['shape'][1]\n",
        "\n",
        "    # Truncate sequences if they're too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = np.array(input_ids, dtype=np.int64).reshape((1, max_length))  # add batch dimension\n",
        "\n",
        "    # Set input tensor to the model\n",
        "    interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "\n",
        "    # Run inference\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Get the output tensor\n",
        "    output_tensor = interpreter.get_tensor(output_details[0]['index'])[:,-1,:]\n",
        "    print(output_tensor)\n",
        "    # Interpret the output\n",
        "    predicted_label = np.argmax(output_tensor, axis=-1).item()\n",
        "\n",
        "    # # Return the classified result\n",
        "    return \"Positive\" if predicted_label == 1 else \"Negative\"\n"
      ],
      "metadata": {
        "id": "bv4-JYGCnBCG"
      },
      "id": "bv4-JYGCnBCG",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_text2(text_1, tokenizer, max_length=1024))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f28Nb8mnwd2",
        "outputId": "55e46ca7-378a-4abe-d333-f93e54d5f882"
      },
      "id": "4f28Nb8mnwd2",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-3.206485   3.0669894]]\n",
            "Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c=0\n",
        "c1=0\n",
        "for i in range(len(t1)):\n",
        "  st=classify_review(text[i], model, tokenizer, device, max_length=train_dataset.max_length)\n",
        "  pr='Negative' if label[i]==0 else'Positive'\n",
        "  print(st,pr)\n",
        "  if st=='Negative':\n",
        "    c1=c1+1\n",
        "  if st==pr:\n",
        "    c=c+1\n",
        "print(c/len(t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcmWP__7nx0M",
        "outputId": "40a17902-e1f5-4c50-9607-658d4c3d868c"
      },
      "id": "wcmWP__7nx0M",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "0.6825095057034221\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-_gXIh1BpcYO"
      },
      "id": "-_gXIh1BpcYO",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}