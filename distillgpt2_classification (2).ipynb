{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Q4nagfePKXLO",
      "metadata": {
        "id": "Q4nagfePKXLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22e43c8a-2830-4fce-8d27-5133260fc315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
      "metadata": {
        "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df403ee7-e952-4afc-dbe0-1f4e0181c3a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib version: 3.7.1\n",
            "numpy version: 1.25.2\n",
            "tiktoken version: 0.7.0\n",
            "torch version: 2.3.0+cu121\n",
            "tensorflow version: 2.15.0\n",
            "pandas version: 2.0.3\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",\n",
        "        \"numpy\",\n",
        "        \"tiktoken\",\n",
        "        \"torch\",\n",
        "        \"tensorflow\", # For OpenAI's pretrained weights\n",
        "        \"pandas\"      # Dataset loading\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} version: {version(p)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
      "metadata": {
        "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecdaa4e6-8913-4b91-f410-b8b3aea78ed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File downloaded and saved as sms_spam_collection/SMSSpamCollection.tsv\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path} already exists. Skipping download and extraction.\")\n",
        "        return\n",
        "\n",
        "    # Downloading the file\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # Unzipping the file\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # Add .tsv file extension\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"File downloaded and saved as {data_file_path}\")\n",
        "\n",
        "download_and_unzip(url, zip_path, extracted_path, data_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
      "metadata": {
        "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "cbb51bf1-1480-498e-814d-b79f2eba71e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "0         0  Go until jurong point, crazy.. Available only ...\n",
              "1         0                      Ok lar... Joking wif u oni...\n",
              "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3         0  U dun say so early hor... U c already then say...\n",
              "4         0  Nah I don't think he goes to usf, he lives aro...\n",
              "...     ...                                                ...\n",
              "5567      1  This is the 2nd time we have tried 2 contact u...\n",
              "5568      0               Will ü b going to esplanade fr home?\n",
              "5569      0  Pity, * was in mood for that. So...any other s...\n",
              "5570      0  The guy did some bitching but I acted like i'd...\n",
              "5571      0                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-556f919e-4aef-4036-bdd5-2d5fe1c04280\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>0</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>0</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>0</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>0</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-556f919e-4aef-4036-bdd5-2d5fe1c04280')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-556f919e-4aef-4036-bdd5-2d5fe1c04280 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-556f919e-4aef-4036-bdd5-2d5fe1c04280');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b46a4763-61cc-479a-95b7-c3faef151ecf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b46a4763-61cc-479a-95b7-c3faef151ecf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b46a4763-61cc-479a-95b7-c3faef151ecf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e2afbb2a-1975-4ad5-8cd9-3e54376f2cc6\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e2afbb2a-1975-4ad5-8cd9-3e54376f2cc6 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df[\"Label\"] = df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
      "metadata": {
        "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afce04d5-8dbf-44db-d88e-a00125100aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "0    4825\n",
            "1     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be4a0a2-9704-4a96-b38f-240339818688",
      "metadata": {
        "id": "7be4a0a2-9704-4a96-b38f-240339818688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26dfb9c5-5ce6-45ed-988a-dfe803e8c96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Series([], Name: count, dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # Count the instances of \"spam\"\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # Randomly sample \"ham' instances to match the number of 'spam' instances\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # Combine ham \"subset\" with \"spam\"\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
      "metadata": {
        "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
      },
      "outputs": [],
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3GmvoxhbC6",
      "metadata": {
        "id": "db3GmvoxhbC6"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/ScamDataNew.csv')\n",
        "testData=pd.read_excel(\"/content/scams13.xlsx\")\n",
        "df.rename(columns={'Text':'Scammer'},inplace=True)\n",
        "testData.rename(columns={'content': 'Scammer'}, inplace=True)\n",
        "testData.rename(columns={'is scam': 'Label'}, inplace=True)\n",
        "balanced_df= pd.concat([df, data], ignore_index=True)\n",
        "balanced_df= pd.concat([balanced_df, testData], ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KcY1_mTWyMpd",
      "metadata": {
        "id": "KcY1_mTWyMpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86472671-86b0-41b5-f21b-66b212e2c642"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Label                                            Scammer scam type  \\\n",
            "0         0  Go until jurong point, crazy.. Available only ...       NaN   \n",
            "1         0                      Ok lar... Joking wif u oni...       NaN   \n",
            "2         1  Free entry in 2 a wkly comp to win FA Cup fina...       NaN   \n",
            "3         0  U dun say so early hor... U c already then say...       NaN   \n",
            "4         0  Nah I don't think he goes to usf, he lives aro...       NaN   \n",
            "...     ...                                                ...       ...   \n",
            "7414      0  EXCITING NEWS! Dwayne 'The Rock' Johnson here!...  Phishing   \n",
            "7415      1  URGENT! Dwayne 'The Rock' Johnson here! I'm gi...  Phishing   \n",
            "7416      0  Hey! Dwayne 'The Rock' Johnson here! To celebr...  Phishing   \n",
            "7417      1  URGENT! Dwayne 'The Rock' Johnson here! I've p...  Phishing   \n",
            "7418      0  EXCITING NEWS! Dwayne 'The Rock' Johnson here!...  Phishing   \n",
            "\n",
            "                                       trick type  \\\n",
            "0                                             NaN   \n",
            "1                                             NaN   \n",
            "2                                             NaN   \n",
            "3                                             NaN   \n",
            "4                                             NaN   \n",
            "...                                           ...   \n",
            "7414  Scarcity, Using Fake Celebrity Endorsements   \n",
            "7415  Scarcity, Using Fake Celebrity Endorsements   \n",
            "7416  Scarcity, Using Fake Celebrity Endorsements   \n",
            "7417  Scarcity, Using Fake Celebrity Endorsements   \n",
            "7418  Scarcity, Using Fake Celebrity Endorsements   \n",
            "\n",
            "                                          attack type  \\\n",
            "0                                                 NaN   \n",
            "1                                                 NaN   \n",
            "2                                                 NaN   \n",
            "3                                                 NaN   \n",
            "4                                                 NaN   \n",
            "...                                               ...   \n",
            "7414                    Intentional spelling mistakes   \n",
            "7415                                 Homograph Attack   \n",
            "7416                                 Homograph Attack   \n",
            "7417  Intentional spelling mistakes, Homograph Attack   \n",
            "7418  Intentional spelling mistakes, Homograph Attack   \n",
            "\n",
            "                                                 reason  \n",
            "0                                                   NaN  \n",
            "1                                                   NaN  \n",
            "2                                                   NaN  \n",
            "3                                                   NaN  \n",
            "4                                                   NaN  \n",
            "...                                                 ...  \n",
            "7414  [\"It's a charity event, not a free giveaway\", ...  \n",
            "7415  [\"Creates a sense of urgency with 'URGENT!' to...  \n",
            "7416  [\"The message does not create a sense of urgen...  \n",
            "7417  ['Uses fake celebrity endorsement to build tru...  \n",
            "7418  [\"It's a legitimate charity campaign\", 'The li...  \n",
            "\n",
            "[7419 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "print(balanced_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uQl0Psdmx15D",
      "metadata": {
        "id": "uQl0Psdmx15D"
      },
      "outputs": [],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # Shuffle the entire DataFrame\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # Calculate split indices\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # Split the DataFrame\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# Test size is implied to be 0.2 as the remainder\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wDcwnHwuX_Q4",
      "metadata": {
        "id": "wDcwnHwuX_Q4"
      },
      "outputs": [],
      "source": [
        "# train_df.rename(columns={'Text': 'Scammer'}, inplace=True)\n",
        "# validation_df.rename(columns={'Text': 'Scammer'}, inplace=True)\n",
        "# test_df.rename(columns={'Text': 'Scammer'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "G-W_Ao0-Zebi",
      "metadata": {
        "id": "G-W_Ao0-Zebi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "outputId": "0bd23da5-e6ad-4c1f-a654-86718c34f4b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                            Scammer scam type  \\\n",
              "0         0  Payment overdue on your card ending 7121 for R...       NaN   \n",
              "1         0  Cbe is really good nowadays:)lot of shop and s...       NaN   \n",
              "2         1  Your unique user ID is 1172. For removal send ...       NaN   \n",
              "3         0                                            Havent.       NaN   \n",
              "4         0                  Boooo you always work. Just quit.       NaN   \n",
              "...     ...                                                ...       ...   \n",
              "5188      0  I got a call from a landline number. . . I am ...       NaN   \n",
              "5189      0                     COME BACK TO TAMPA FFFFUUUUUUU       NaN   \n",
              "5190      1  URGENT: Your Apple acc0unt has been compromize...  Phishing   \n",
              "5191      0  God picked up a flower and dippeditinaDEW, lov...       NaN   \n",
              "5192      0  Indians r poor but India is not a poor country...       NaN   \n",
              "\n",
              "                                             trick type  \\\n",
              "0                                                   NaN   \n",
              "1                                                   NaN   \n",
              "2                                                   NaN   \n",
              "3                                                   NaN   \n",
              "4                                                   NaN   \n",
              "...                                                 ...   \n",
              "5188                                                NaN   \n",
              "5189                                                NaN   \n",
              "5190  Authority, Using Fake Reviews or Ratings to Bu...   \n",
              "5191                                                NaN   \n",
              "5192                                                NaN   \n",
              "\n",
              "                                          attack type  \\\n",
              "0                                                 NaN   \n",
              "1                                                 NaN   \n",
              "2                                                 NaN   \n",
              "3                                                 NaN   \n",
              "4                                                 NaN   \n",
              "...                                               ...   \n",
              "5188                                              NaN   \n",
              "5189                                              NaN   \n",
              "5190  Homograph Attack, Intentional spelling mistakes   \n",
              "5191                                              NaN   \n",
              "5192                                              NaN   \n",
              "\n",
              "                                                 reason  \n",
              "0                                                   NaN  \n",
              "1                                                   NaN  \n",
              "2                                                   NaN  \n",
              "3                                                   NaN  \n",
              "4                                                   NaN  \n",
              "...                                                 ...  \n",
              "5188                                                NaN  \n",
              "5189                                                NaN  \n",
              "5190  [\"Uses 'Authority' by claiming to be from 'App...  \n",
              "5191                                                NaN  \n",
              "5192                                                NaN  \n",
              "\n",
              "[5193 rows x 6 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afcffa40-878b-4c9d-8660-37a9ea8c1c31\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Scammer</th>\n",
              "      <th>scam type</th>\n",
              "      <th>trick type</th>\n",
              "      <th>attack type</th>\n",
              "      <th>reason</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Payment overdue on your card ending 7121 for R...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Cbe is really good nowadays:)lot of shop and s...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Your unique user ID is 1172. For removal send ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Havent.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Boooo you always work. Just quit.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5188</th>\n",
              "      <td>0</td>\n",
              "      <td>I got a call from a landline number. . . I am ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5189</th>\n",
              "      <td>0</td>\n",
              "      <td>COME BACK TO TAMPA FFFFUUUUUUU</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5190</th>\n",
              "      <td>1</td>\n",
              "      <td>URGENT: Your Apple acc0unt has been compromize...</td>\n",
              "      <td>Phishing</td>\n",
              "      <td>Authority, Using Fake Reviews or Ratings to Bu...</td>\n",
              "      <td>Homograph Attack, Intentional spelling mistakes</td>\n",
              "      <td>[\"Uses 'Authority' by claiming to be from 'App...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5191</th>\n",
              "      <td>0</td>\n",
              "      <td>God picked up a flower and dippeditinaDEW, lov...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5192</th>\n",
              "      <td>0</td>\n",
              "      <td>Indians r poor but India is not a poor country...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5193 rows × 6 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afcffa40-878b-4c9d-8660-37a9ea8c1c31')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afcffa40-878b-4c9d-8660-37a9ea8c1c31 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afcffa40-878b-4c9d-8660-37a9ea8c1c31');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-702defd9-0e42-4d57-a351-7ad80847d857\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-702defd9-0e42-4d57-a351-7ad80847d857')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-702defd9-0e42-4d57-a351-7ad80847d857 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_16733a19-c1a9-40cb-963a-321b083aa492\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('train_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_16733a19-c1a9-40cb-963a-321b083aa492 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('train_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 5193,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Scammer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4931,\n        \"samples\": [\n          \"Hello, Mr. Gupta, this is Ananya Singh from your bank's customer care. We're pleased to inform you that your credit card annual fee will be waived off this year due to your valued patronage. To proceed, could you please verify a few details? Your card number ends in 9876 XXXX, and your name is Anil Gupta, correct? Kindly share the OTP you'll receive to finalize the fee waiver process.\",\n          \"Bored of speed dating? Try SPEEDCHAT, txt SPEEDCHAT to 80155, if you don't like em txt SWAP and get a new chatter! Chat80155 POBox36504W45WQ 150p/msg rcd 16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"scam type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Phishing\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trick type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 107,\n        \"samples\": [\n          \"Authority, Flattery\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"attack type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Intentional spelling mistakes, Homograph Attack\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reason\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 579,\n        \"samples\": [\n          \"['Uses a sense of urgency to create a false sense of panic', 'Uses a fake URL with a homograph attack (\\u0430 instead of a) to trick the user', 'Claims to be from a trusted authority (Amazon Security Team) to build rapport', 'Asks the user to verify sensitive information', 'The message is unsolicited and targets the user with a generic greeting']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "train_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
      "metadata": {
        "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7"
      },
      "outputs": [],
      "source": [
        "from transformers import GPT2Tokenizer, GPT2Model\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2',max_length=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ff0f6b2-376b-4740-8858-55b60784be73",
      "metadata": {
        "id": "0ff0f6b2-376b-4740-8858-55b60784be73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b83ef20-18be-48ab-d72f-429897deb7e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[42, 13, 314, 481, 1908, 340, 757]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "tokenizer.encode(\"K. I will sent it again\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
      "metadata": {
        "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # Pre-tokenize texts\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Scammer\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # Truncate sequences if they are longer than max_length\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # Pad sequences to the longest sequence\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        # Assuming label is a string, convert it to an integer before creating the tensor\n",
        "        label = int(self.data.iloc[index][\"Label\"])\n",
        "        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zE4J0x-CUjZr",
      "metadata": {
        "id": "zE4J0x-CUjZr"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Load the ScamData.csv file\n",
        "\n",
        "\n",
        "# # Split the data into train and test sets (80% train, 20% test)\n",
        "# train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Further split the train data into train and validation sets (80% train, 20% validation)\n",
        "# train_data, validation_data = train_test_split(train_data, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Save the split data into separate CSV files\n",
        "# train_data.to_csv('train1.csv', index=False)\n",
        "# test_data.to_csv('test1.csv', index=False)\n",
        "# validation_data.to_csv('validation1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4EVDgw7-Zq_Q",
      "metadata": {
        "id": "4EVDgw7-Zq_Q"
      },
      "outputs": [],
      "source": [
        "# merged_df = pd.concat([train_data, train_df], ignore_index=True)\n",
        "# merged_df=pd.concat([merged_df,test])\n",
        "# merged_df.to_csv('train2.csv',index=False)\n",
        "# merged_df1 = pd.concat([test_data, test_df], ignore_index=True)\n",
        "# merged_df1.to_csv('test2.csv',index=False)\n",
        "# merged_df2 = pd.concat([validation_data, validation_df], ignore_index=True)\n",
        "# merged_df2.to_csv('validation2.csv',index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uzj85f8ou82h",
      "metadata": {
        "id": "uzj85f8ou82h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b889f68a-7b5f-441d-a9a3-507a6ccffd44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<__main__.SpamDataset object at 0x7eb9e747b4f0>\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
        "print(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
      "metadata": {
        "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
      },
      "outputs": [],
      "source": [
        "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
        "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
      "metadata": {
        "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
      "metadata": {
        "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b995501-53ab-4ee9-d526-a19d514709e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7eb9e74791b0>\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n",
            "Input batch dimensions: torch.Size([8, 257])\n",
            "Label batch dimensions torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(train_loader)\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "    print(\"Input batch dimensions:\", input_batch.shape)\n",
        "    print(\"Label batch dimensions\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Hu0OyC7Vu4vZ",
      "metadata": {
        "id": "Hu0OyC7Vu4vZ"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "IZfw-TYD2zTj",
      "metadata": {
        "id": "IZfw-TYD2zTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca53dbc4-d431-46aa-8c79-11ee3b936ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "649 training batches\n",
            "93 validation batches\n",
            "186 test batches\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)} training batches\")\n",
        "print(f\"{len(val_loader)} validation batches\")\n",
        "print(f\"{len(test_loader)} test batches\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
      "metadata": {
        "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
      },
      "outputs": [],
      "source": [
        "# CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "# INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "# BASE_CONFIG = {\n",
        "#     \"vocab_size\": 50257,     # Vocabulary size\n",
        "#     \"context_length\": 1024,  # Context length\n",
        "#     \"drop_rate\": 0.0,        # Dropout rate\n",
        "#     \"qkv_bias\": True         # Query-key-value bias\n",
        "# }\n",
        "\n",
        "# model_configs = {\n",
        "#     \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "#     \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "#     \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "#     \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "# }\n",
        "\n",
        "# BASE_CONFIG.update(model_configs[CHOOSE_MODEL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "022a649a-44f5-466c-8a8e-326c063384f5",
      "metadata": {
        "id": "022a649a-44f5-466c-8a8e-326c063384f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "f667679113a9478db7243f311608e899",
            "64a9ac4675f0427a9b50d0aa238a36ce",
            "9fb76f37cc54483eabb6cdee5ca86149",
            "7a72cbd2222744c3aa8a25c54b811bd5",
            "2655f9d09dc743609a0b8314884a072c",
            "0881cffe64bb43a4b50f35e9f7692b11",
            "b8b7e980ce504205b70175f5fe36cc5e",
            "6dd1ab6864754d778f76e6fa3409310e",
            "832fb971254e49c7b0670b7ed7efdfa0",
            "e2cb10b3e007406687ef78820ea8b2a1",
            "bf01ae97a5b74b0785144e87b82a4375"
          ]
        },
        "outputId": "18e0b599-63d2-478a-dfff-617c0770851a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f667679113a9478db7243f311608e899"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# from gpt_download import download_and_load_gpt2\n",
        "# from utils import GPTModel, load_weights_into_gpt\n",
        "\n",
        "# model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "# settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "# model = GPTModel(BASE_CONFIG)\n",
        "# load_weights_into_gpt(model, params)\n",
        "# model.eval();\n",
        "model = GPT2Model.from_pretrained('distilgpt2')\n",
        "model.eval();\n",
        "text = \"Replace me by any text you'd like.\"\n",
        "encoded_input = tokenizer(text, return_tensors='pt')\n",
        "output = model(**encoded_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
      "metadata": {
        "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330"
      },
      "outputs": [],
      "source": [
        "# from utils import (\n",
        "#     generate_text_simple,\n",
        "#     text_to_token_ids,\n",
        "#     token_ids_to_text\n",
        "# )\n",
        "\n",
        "\n",
        "# text_1 = \"Every effort moves you\"\n",
        "\n",
        "# token_ids = generate_text_simple(\n",
        "#     model=model,\n",
        "#     idx=text_to_token_ids(text_1, tokenizer),\n",
        "#     max_new_tokens=15,\n",
        "#     context_size=BASE_CONFIG[\"context_length\"]\n",
        "# )\n",
        "\n",
        "# print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
      "metadata": {
        "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c"
      },
      "outputs": [],
      "source": [
        "# text_2 = (\n",
        "#     \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "#     \" 'You are a winner you have been specially\"\n",
        "#     \" selected to receive $1000 cash or a $2000 award.'\"\n",
        "#     \" Answer with 'yes' or 'no'.\"\n",
        "# )\n",
        "\n",
        "# token_ids = generate_text_simple(\n",
        "#     model=model,\n",
        "#     idx=text_to_token_ids(text_2, tokenizer),\n",
        "#     max_new_tokens=23,\n",
        "#     context_size=BASE_CONFIG[\"context_length\"]\n",
        "# )\n",
        "\n",
        "# print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
      "metadata": {
        "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a243b649-80b0-4fdf-f1fe-af34b0f9e2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT2Model(\n",
            "  (wte): Embedding(50257, 768)\n",
            "  (wpe): Embedding(1024, 768)\n",
            "  (drop): Dropout(p=0.1, inplace=False)\n",
            "  (h): ModuleList(\n",
            "    (0-5): 6 x GPT2Block(\n",
            "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (attn): GPT2Attention(\n",
            "        (c_attn): Conv1D()\n",
            "        (c_proj): Conv1D()\n",
            "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (mlp): GPT2MLP(\n",
            "        (c_fc): Conv1D()\n",
            "        (c_proj): Conv1D()\n",
            "        (act): NewGELUActivation()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fkMWFl-0etea",
      "metadata": {
        "id": "fkMWFl-0etea"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
      "metadata": {
        "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=768, out_features=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
      "metadata": {
        "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
      },
      "outputs": [],
      "source": [
        "for param in model.h[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.ln_f.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
      "metadata": {
        "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea2e2f9-2bac-438f-ce2a-9cd919d2ffd3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs: tensor([[5211,  345,  423,  640]])\n",
            "Inputs dimensions: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"Inputs:\", inputs)\n",
        "print(\"Inputs dimensions:\", inputs.shape) # shape: (batch_size, num_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
      "metadata": {
        "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f286344-540e-4465-a7ca-39a2ef891b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outputs:\n",
            " BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[ 0.0317,  0.3798, -0.0624,  ..., -0.2326,  0.1347, -0.1138],\n",
            "         [-0.0347, -0.2202, -0.3072,  ..., -0.1627, -0.0487,  0.3298],\n",
            "         [ 0.3939,  0.0082, -1.3061,  ..., -0.2604,  0.4336,  0.2004],\n",
            "         [ 0.8117, -0.3543, -1.2459,  ...,  0.2571,  0.3096,  0.1915]]]), past_key_values=((tensor([[[[-1.0994,  2.3177,  1.2211,  ..., -1.5311, -0.7902,  1.1364],\n",
            "          [-1.8806,  2.4583,  2.5536,  ..., -0.9601, -1.9421,  1.0221],\n",
            "          [-1.8011,  2.8406,  2.3653,  ..., -0.8063, -2.8522,  1.6565],\n",
            "          [-3.1518,  2.7217,  2.8224,  ..., -0.0862, -2.5494,  1.6161]],\n",
            "\n",
            "         [[ 0.5092, -0.7858, -0.5326,  ..., -0.4770,  2.2333,  0.0144],\n",
            "          [-0.7958, -2.0695, -1.1748,  ..., -1.7790,  4.8768,  0.0153],\n",
            "          [ 0.5037,  0.1521, -1.1640,  ..., -1.6524,  3.3693,  0.3842],\n",
            "          [-0.7979,  0.4668, -1.9158,  ..., -2.1877,  3.5881, -1.2470]],\n",
            "\n",
            "         [[-0.0729, -0.5676,  0.7095,  ..., -1.3057, -0.9625,  0.6724],\n",
            "          [ 0.1335,  0.4458,  0.2670,  ..., -1.9813,  0.7042,  0.8648],\n",
            "          [ 0.4054, -0.1860,  0.6032,  ..., -2.1377,  0.9008,  1.7050],\n",
            "          [ 0.2318,  0.8402,  1.0727,  ..., -3.0906,  0.8168,  0.7011]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.5203,  0.1938,  0.0135,  ...,  0.7735,  0.7083,  0.7473],\n",
            "          [-0.1835,  0.2189,  0.1790,  ...,  1.3821, -0.1185,  0.2298],\n",
            "          [-0.1665,  0.1097,  0.1579,  ...,  1.0807,  0.2774,  0.2035],\n",
            "          [-0.1789,  0.3989, -0.6721,  ...,  1.4048,  0.0651,  0.4866]],\n",
            "\n",
            "         [[ 1.1185,  0.9340, -0.5405,  ..., -0.0717,  1.3198, -0.7931],\n",
            "          [ 1.4088,  0.9138, -0.4507,  ..., -1.0003,  1.4953, -0.1452],\n",
            "          [ 1.3764,  0.8609, -0.0801,  ..., -1.2334,  1.6915, -0.8859],\n",
            "          [ 0.5833,  0.9210, -1.4428,  ..., -1.0590,  1.0308, -1.2269]],\n",
            "\n",
            "         [[ 0.7397, -0.1698, -0.3939,  ...,  0.0269,  0.3999,  1.5943],\n",
            "          [-0.0160, -0.0265, -0.0690,  ...,  0.8181,  0.6516,  1.4631],\n",
            "          [-0.4795, -0.1079, -0.1000,  ...,  0.2464,  0.8334,  1.4650],\n",
            "          [-0.7434, -0.1786, -0.0562,  ...,  0.3092,  0.5362,  1.2570]]]]), tensor([[[[-0.0927,  0.0663, -0.0393,  ...,  0.0158, -0.0686,  0.1528],\n",
            "          [ 0.1106,  0.3329, -0.0367,  ...,  0.3016, -0.0907,  0.1380],\n",
            "          [ 0.3633, -0.0878,  0.1556,  ...,  0.0125,  0.1012,  0.0342],\n",
            "          [ 0.0242, -0.0782, -0.0033,  ..., -0.0166, -0.1403,  0.3316]],\n",
            "\n",
            "         [[ 0.2051,  0.1047, -0.2224,  ..., -0.3651, -0.4282,  0.0109],\n",
            "          [ 0.2458, -0.0359,  0.0066,  ...,  0.1054,  0.0959, -0.2393],\n",
            "          [ 0.2787,  0.2653,  0.0563,  ...,  0.0756,  0.1712,  0.0680],\n",
            "          [ 0.3717,  0.1320,  0.0104,  ...,  0.2935, -0.0558, -0.0404]],\n",
            "\n",
            "         [[ 0.1104, -0.0352, -0.0957,  ...,  0.0989,  0.1138, -0.1043],\n",
            "          [-0.3139,  0.1159, -0.0169,  ..., -0.1194, -0.0912, -0.2851],\n",
            "          [ 0.0662,  0.3527,  0.4222,  ...,  0.1442,  0.2596,  0.1277],\n",
            "          [-0.1049,  0.0925,  0.1127,  ...,  0.2650,  0.0721, -0.0449]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1027, -0.1555,  0.1118,  ...,  0.0537,  0.0316, -0.2227],\n",
            "          [-0.4255,  0.2952,  0.1336,  ..., -0.3293, -0.2193, -0.2314],\n",
            "          [-0.2000,  0.1364,  0.1054,  ...,  0.0699, -0.4086, -0.0906],\n",
            "          [-0.2200, -0.0150,  0.0839,  ...,  0.1213,  0.0862,  0.0120]],\n",
            "\n",
            "         [[ 0.1034,  0.0402, -0.0699,  ...,  0.2229,  0.1055, -0.1393],\n",
            "          [-0.3551, -0.0303, -0.1555,  ..., -0.0427, -0.4254,  0.4013],\n",
            "          [-0.3410, -0.0716,  0.1310,  ..., -0.1751, -0.4024, -0.0841],\n",
            "          [ 0.0232, -0.3257, -0.0547,  ..., -0.3219, -0.4354, -0.1067]],\n",
            "\n",
            "         [[-0.1035, -0.2343,  0.0624,  ..., -0.0081, -0.1137, -0.0274],\n",
            "          [ 0.0317, -0.1011, -0.2565,  ...,  0.0784,  0.1664,  0.2011],\n",
            "          [ 0.0049, -0.0913, -0.0624,  ...,  0.1307,  0.3298, -0.0034],\n",
            "          [ 0.1654,  0.1101, -0.1433,  ...,  0.1782,  0.0272,  0.1229]]]])), (tensor([[[[-0.0681, -0.9576,  0.2554,  ..., -0.9553,  0.2448, -0.0369],\n",
            "          [-0.0666, -3.7450,  0.8711,  ..., -0.4469,  0.8311, -0.1503],\n",
            "          [ 0.4307, -4.6380,  0.2501,  ..., -1.4318, -0.3733, -0.1510],\n",
            "          [ 0.0403, -4.1753, -0.3934,  ..., -1.5649, -0.2959,  0.5440]],\n",
            "\n",
            "         [[-0.7328, -0.0916, -0.6165,  ...,  0.9057, -0.6905, -0.5756],\n",
            "          [-1.3051, -1.1779, -0.6271,  ..., -1.3817,  1.3558,  0.0574],\n",
            "          [-0.4761, -0.9883, -1.2769,  ...,  0.3831,  1.3969,  1.1362],\n",
            "          [ 0.0889,  0.9227, -1.3348,  ...,  0.3598,  0.2343,  1.1102]],\n",
            "\n",
            "         [[ 1.2525,  2.2889,  3.5066,  ...,  0.8366,  1.6315, -0.8437],\n",
            "          [-2.3646,  5.1498, -0.2751,  ..., -1.1324,  3.2218, -0.4822],\n",
            "          [-3.3021,  4.7810, -3.0246,  ..., -1.8969,  2.6256, -0.9134],\n",
            "          [-2.3180,  4.6976, -0.1915,  ..., -1.9140,  0.9310, -0.4771]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7319, -2.1832, -2.6717,  ...,  0.8375,  1.0664,  2.2400],\n",
            "          [-1.2098, -1.5288, -2.3060,  ..., -0.2110, -2.9571,  2.4994],\n",
            "          [-1.3599, -0.2950, -1.4021,  ..., -1.2488, -3.4171,  2.3265],\n",
            "          [-3.1541, -0.9617, -1.3038,  ..., -1.1194, -3.8415,  2.1358]],\n",
            "\n",
            "         [[ 1.9086,  0.3542,  0.8555,  ..., -0.2857, -1.0487, -0.0342],\n",
            "          [ 0.8028,  1.8287,  1.1212,  ...,  0.1601, -2.5802, -2.1595],\n",
            "          [ 1.1970,  0.6734,  0.8478,  ..., -0.2881, -2.3197, -2.1556],\n",
            "          [ 1.6640,  0.6058,  2.1144,  ...,  0.3181, -2.5842, -2.6771]],\n",
            "\n",
            "         [[-0.0954,  0.3616, -0.6293,  ...,  0.0484,  0.5727,  0.0217],\n",
            "          [ 0.3363,  0.8636, -0.5292,  ..., -1.4270,  0.6148,  0.4875],\n",
            "          [ 0.6171,  0.7749, -0.2748,  ..., -1.0551,  1.4376, -0.8602],\n",
            "          [ 0.0304,  0.7082, -0.4070,  ..., -1.5477,  1.0587, -0.6093]]]]), tensor([[[[ 0.0176, -0.1690, -0.0360,  ...,  0.0483,  0.0248, -0.3053],\n",
            "          [ 0.5920,  0.1992, -0.8124,  ..., -0.2347, -0.1058,  1.3104],\n",
            "          [ 1.0309,  0.1254,  0.5674,  ..., -0.7156,  0.5780,  0.9244],\n",
            "          [ 0.7093, -0.4388,  0.6309,  ...,  0.8686,  0.8584,  1.1890]],\n",
            "\n",
            "         [[ 0.1173, -0.0342,  0.0060,  ..., -0.0695,  0.0232,  0.0558],\n",
            "          [ 0.5655,  1.1527,  0.5392,  ..., -0.4597, -0.1173,  0.5117],\n",
            "          [ 0.0941, -0.0799,  0.1868,  ...,  0.2316,  0.2738,  0.2865],\n",
            "          [ 0.1484,  0.0129, -0.1084,  ...,  0.5645,  0.0682, -0.1465]],\n",
            "\n",
            "         [[ 0.0362, -0.5357, -0.0217,  ..., -0.1144, -0.0194, -0.0502],\n",
            "          [-0.1779, -0.3550,  0.9347,  ..., -0.2986,  0.5765, -0.0177],\n",
            "          [ 0.3083, -0.1824,  0.4158,  ..., -0.8446,  0.2144, -0.1742],\n",
            "          [-0.4114, -1.3042, -0.0956,  ...,  0.1896, -0.2182, -0.1440]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0137, -0.0724,  0.5860,  ..., -0.0355,  0.0267, -0.1258],\n",
            "          [-0.1662, -0.3600,  1.1416,  ..., -0.0034, -0.3248,  0.4627],\n",
            "          [-0.1481, -0.4147,  0.9514,  ...,  0.1686,  0.0626, -0.1676],\n",
            "          [-0.1759, -0.1196,  0.5285,  ...,  0.0334, -0.6886,  1.5523]],\n",
            "\n",
            "         [[ 0.0629, -0.0560, -0.1243,  ...,  0.0072, -0.0773,  0.0264],\n",
            "          [ 1.2557,  0.2165, -0.4570,  ..., -0.2375, -0.4805, -0.5056],\n",
            "          [-0.6177,  0.8765,  0.0905,  ..., -0.0430, -0.8694, -0.6155],\n",
            "          [ 0.0751,  0.3846, -0.4446,  ...,  0.1133, -0.2211, -0.6065]],\n",
            "\n",
            "         [[ 0.1146,  0.0827,  0.0034,  ..., -0.0783, -0.0477,  0.0189],\n",
            "          [-0.9209, -0.1887,  0.7414,  ..., -0.4128, -0.6410,  0.4610],\n",
            "          [-0.5540, -1.1379, -0.1114,  ..., -0.7042, -0.6408,  1.2922],\n",
            "          [-0.2118, -0.3027, -0.5725,  ..., -0.8114, -0.7926,  0.2100]]]])), (tensor([[[[-8.9602e-01, -1.3569e-01,  2.9923e-01,  ..., -9.3901e-01,\n",
            "            1.3114e-01, -2.8111e+00],\n",
            "          [ 1.1907e+00,  1.6170e+00, -7.7017e-01,  ..., -1.2086e+00,\n",
            "           -1.2116e+00,  3.2948e+00],\n",
            "          [ 3.4955e+00,  1.1764e+00,  6.8994e-02,  ..., -1.4588e+00,\n",
            "           -9.3718e-01,  3.0748e+00],\n",
            "          [ 1.9663e+00,  6.3227e-01, -2.7519e+00,  ..., -2.9278e-01,\n",
            "           -2.5410e+00,  2.2451e+00]],\n",
            "\n",
            "         [[ 2.9141e-01, -1.0826e-01,  4.8923e-01,  ..., -1.1609e-01,\n",
            "           -2.3015e-01, -2.0243e+00],\n",
            "          [-2.0832e+00, -1.5183e+00,  2.7534e+00,  ..., -7.0893e-01,\n",
            "           -8.9967e-01,  4.9116e+00],\n",
            "          [-2.7748e+00,  7.3217e-02,  3.0841e+00,  ..., -1.5537e+00,\n",
            "           -6.3105e-01,  6.8027e+00],\n",
            "          [-4.3619e+00, -9.7777e-02,  3.7183e+00,  ..., -3.1349e+00,\n",
            "           -5.1591e-01,  5.6819e+00]],\n",
            "\n",
            "         [[ 1.3885e-01, -5.2047e-01, -1.5626e-01,  ...,  7.4526e-02,\n",
            "            2.1462e-01, -1.1265e-01],\n",
            "          [-7.7745e-01,  1.0990e+00,  2.9928e-02,  ...,  3.3580e-01,\n",
            "           -2.4214e+00,  1.7742e-01],\n",
            "          [ 6.2123e-01,  1.4879e+00,  7.2672e-01,  ...,  1.1171e+00,\n",
            "            7.7623e-01,  1.1632e+00],\n",
            "          [-1.0059e-01,  2.4671e+00, -6.4863e-01,  ..., -5.3094e-01,\n",
            "           -6.4362e-03,  2.1230e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7389e-01, -2.6983e-02,  1.0399e-01,  ...,  1.2925e+00,\n",
            "            1.8300e-01,  1.7379e+00],\n",
            "          [ 1.2031e+00, -1.2043e+00, -1.9203e-01,  ..., -3.2542e-01,\n",
            "           -1.0897e+00, -5.4384e-02],\n",
            "          [ 1.2646e-01,  1.1713e+00,  2.1989e-01,  ..., -1.0004e+00,\n",
            "            1.8469e-01, -6.8177e-01],\n",
            "          [ 1.3794e+00,  1.1156e+00,  9.0454e-02,  ..., -8.4058e-01,\n",
            "           -1.1143e+00, -2.1326e+00]],\n",
            "\n",
            "         [[-2.6439e-01, -1.1057e-01,  7.8645e-02,  ...,  1.2413e-01,\n",
            "           -3.0583e-02, -2.5451e-02],\n",
            "          [-8.6868e-01, -1.3207e-01,  9.4414e-01,  ...,  1.1415e+00,\n",
            "            1.2199e+00, -7.1621e-01],\n",
            "          [ 9.1334e-01, -3.1331e-01,  7.5759e-01,  ...,  7.7579e-01,\n",
            "            1.4853e+00, -1.7200e-01],\n",
            "          [-8.4257e-01, -6.4786e-01,  4.2514e-01,  ...,  8.9767e-01,\n",
            "            3.0579e-01,  1.1185e+00]],\n",
            "\n",
            "         [[ 3.2939e+00,  1.2737e+00, -2.6143e+00,  ..., -2.6139e+00,\n",
            "           -4.1023e+00, -1.4728e+00],\n",
            "          [ 9.0146e-01, -8.5714e-01,  2.4790e+00,  ..., -4.8570e+00,\n",
            "            6.3461e+00, -1.6875e+00],\n",
            "          [-3.4742e+00, -1.4356e+00,  3.3368e+00,  ..., -6.4549e+00,\n",
            "            6.5865e+00,  1.5555e+00],\n",
            "          [-6.1122e+00, -1.9499e+00,  3.7579e+00,  ..., -4.6001e+00,\n",
            "            7.4423e+00, -1.6588e+00]]]]), tensor([[[[ 5.5998e-02, -6.6257e-03, -6.5010e-03,  ...,  4.8181e-02,\n",
            "           -6.9929e-02,  2.7757e-02],\n",
            "          [ 1.0349e-01, -3.5989e-01,  6.3237e-01,  ..., -3.3800e-01,\n",
            "            2.2566e-01,  5.1063e-02],\n",
            "          [-9.7072e-02, -3.4430e-02, -1.8466e-01,  ...,  7.3676e-02,\n",
            "           -1.2534e-02, -1.1618e-01],\n",
            "          [ 2.5826e-01, -3.8203e-02,  4.0711e-01,  ...,  4.7407e-01,\n",
            "           -1.5388e-01, -3.3128e-01]],\n",
            "\n",
            "         [[-5.8469e-02,  3.9366e-02, -1.8721e-01,  ..., -3.0980e-02,\n",
            "            3.8073e-03,  4.0079e-02],\n",
            "          [ 4.6607e-01, -4.8116e-01, -4.9975e-01,  ..., -1.9396e-01,\n",
            "            5.9776e-01, -1.2309e-01],\n",
            "          [ 4.7887e-01, -7.3403e-03, -1.6384e-01,  ..., -1.9840e-01,\n",
            "            2.7010e-01, -5.3951e-01],\n",
            "          [ 6.0293e-01,  7.7354e-01,  8.5395e-02,  ...,  5.7570e-01,\n",
            "           -1.9134e-01, -3.1223e-01]],\n",
            "\n",
            "         [[ 8.4094e-03,  2.7557e-02, -4.6079e-03,  ..., -5.8248e-03,\n",
            "            2.0592e-02,  1.9010e-02],\n",
            "          [-9.6431e-01, -9.3075e-02,  1.9871e-01,  ...,  2.6961e-02,\n",
            "            4.3970e-02,  5.0140e-01],\n",
            "          [-2.1477e-01,  2.0226e-01,  2.3988e-01,  ...,  2.5918e-01,\n",
            "           -2.4009e-01, -2.4050e-02],\n",
            "          [-2.1256e-02, -6.2910e-01,  3.9170e-01,  ...,  3.9487e-01,\n",
            "            8.3892e-01, -2.7721e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.4231e-02,  1.1699e-02, -1.9299e-02,  ...,  3.0883e-02,\n",
            "            4.5838e-02, -5.3680e-02],\n",
            "          [ 2.3163e-01,  2.2927e-01,  4.9230e-01,  ..., -4.2944e-01,\n",
            "           -5.6285e-01, -1.0160e-01],\n",
            "          [ 4.3160e-01,  2.4907e-01,  1.5907e-01,  ..., -5.9642e-01,\n",
            "            1.7609e-01, -2.2015e-01],\n",
            "          [-3.5890e-01, -2.1289e-01, -5.8497e-01,  ..., -5.2527e-03,\n",
            "           -1.1994e+00,  5.4692e-02]],\n",
            "\n",
            "         [[ 3.7387e-03, -3.6218e-02,  2.0497e-02,  ..., -2.5496e-02,\n",
            "            1.7708e-02, -1.0586e-02],\n",
            "          [ 4.4690e-01, -1.5006e-01, -7.6655e-02,  ...,  4.4707e-01,\n",
            "            5.6704e-01,  7.5280e-01],\n",
            "          [-2.1784e-01, -1.7578e-01,  3.1518e-01,  ..., -1.6399e-01,\n",
            "           -2.8940e-01,  1.2085e-01],\n",
            "          [-3.6319e-01, -2.6417e-01, -3.9617e-01,  ...,  1.9103e-01,\n",
            "           -1.6942e-01, -5.8989e-01]],\n",
            "\n",
            "         [[ 1.8831e-02, -1.5601e-02,  4.9629e-02,  ..., -4.6072e-02,\n",
            "           -2.3217e-02,  1.0508e-01],\n",
            "          [ 3.7121e-02,  1.3207e-01, -3.7628e-01,  ...,  3.3865e-01,\n",
            "            7.0841e-02, -6.8748e-01],\n",
            "          [-4.8139e-01, -4.4947e-01, -4.5318e-01,  ..., -2.0133e-01,\n",
            "           -3.3574e-01,  9.0055e-03],\n",
            "          [ 1.4828e-04, -6.7162e-01,  6.3698e-01,  ...,  1.1548e-01,\n",
            "            2.8438e-01, -4.3630e-01]]]])), (tensor([[[[ 1.0843e+00, -2.1825e-01, -5.4299e-03,  ...,  5.0113e-01,\n",
            "            5.9111e-01, -2.2642e-01],\n",
            "          [-1.7929e+00, -4.7430e-01,  1.4042e+00,  ...,  1.3280e+00,\n",
            "           -4.6601e+00, -2.5070e-02],\n",
            "          [-2.4868e+00, -1.2116e+00,  7.6044e-01,  ...,  1.3121e+00,\n",
            "           -4.6694e+00, -9.3148e-02],\n",
            "          [-4.0994e+00,  1.3468e-01,  1.6003e-02,  ...,  1.5497e-01,\n",
            "           -4.8851e+00,  9.9715e-01]],\n",
            "\n",
            "         [[-1.2957e-01, -8.5925e-02,  9.4183e-02,  ..., -2.0400e-02,\n",
            "           -5.0523e-01, -1.6514e-01],\n",
            "          [-1.0036e+00,  1.2777e+00, -1.2591e+00,  ...,  6.3288e-01,\n",
            "            6.2500e-01,  1.6228e+00],\n",
            "          [-9.2947e-01,  2.3571e+00, -1.0647e+00,  ...,  9.1455e-01,\n",
            "            7.4849e-01,  4.3606e-01],\n",
            "          [-7.1194e-01, -1.3419e-02, -2.6503e-01,  ...,  9.4808e-01,\n",
            "            1.3386e+00, -1.3407e-01]],\n",
            "\n",
            "         [[ 1.7037e-01,  1.0291e-01,  9.0266e-01,  ..., -3.0637e-01,\n",
            "            2.1851e-01, -3.2143e-01],\n",
            "          [-9.0569e-02, -1.8662e+00, -7.5240e-01,  ..., -3.0804e-01,\n",
            "           -1.3469e+00,  9.7671e-01],\n",
            "          [-9.7927e-01, -1.4478e+00, -5.3132e-01,  ..., -1.7186e+00,\n",
            "           -2.3182e+00, -9.2422e-01],\n",
            "          [ 1.9355e-01, -4.3971e-01, -5.6215e-02,  ..., -1.5691e+00,\n",
            "           -2.8220e+00,  1.7618e+00]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0164e-01, -5.4238e-02, -2.6943e-01,  ...,  1.1624e-01,\n",
            "            3.3402e-02,  7.0805e-02],\n",
            "          [-1.4074e+00, -8.7196e-01, -1.2740e+00,  ...,  1.3015e+00,\n",
            "           -9.2447e-02, -5.5753e-01],\n",
            "          [-1.5141e+00, -9.3250e-01, -1.7078e-01,  ...,  2.2503e-01,\n",
            "           -2.0826e-01, -4.9833e-01],\n",
            "          [ 1.6298e-01,  1.7664e-02,  2.5039e-01,  ..., -2.4168e-01,\n",
            "            8.8188e-01,  1.0481e+00]],\n",
            "\n",
            "         [[-1.3689e-01, -1.4646e+00,  1.3283e-01,  ..., -9.3659e-02,\n",
            "            2.2276e-03,  4.8145e-01],\n",
            "          [ 2.0143e-01,  2.3817e+00,  2.8823e-02,  ...,  5.9236e-01,\n",
            "            2.3007e-01,  6.0882e-01],\n",
            "          [-7.8207e-02,  4.6015e+00, -9.8495e-01,  ...,  2.2609e-02,\n",
            "           -1.2510e-02, -1.6533e+00],\n",
            "          [ 5.3288e-01,  4.0215e+00,  1.8132e-01,  ...,  4.1790e-01,\n",
            "            2.1645e-01,  5.3039e-01]],\n",
            "\n",
            "         [[ 1.3719e-01,  9.1955e-02, -1.4455e-02,  ...,  6.0919e-01,\n",
            "           -6.9746e-02,  9.6950e-02],\n",
            "          [ 6.0999e-01, -3.1203e-01, -8.3041e-01,  ...,  1.2039e+00,\n",
            "            2.0686e-01, -6.0890e-01],\n",
            "          [-1.7948e+00, -9.7800e-01,  8.3281e-03,  ..., -5.9581e-01,\n",
            "            1.0960e+00,  3.1883e-01],\n",
            "          [-1.5346e+00, -1.4032e+00,  1.1555e+00,  ..., -9.1806e-02,\n",
            "            1.4855e+00,  2.9930e-01]]]]), tensor([[[[-3.3236e-02,  1.9731e-02, -9.7840e-03,  ...,  3.1800e-02,\n",
            "            2.7898e-03,  4.1774e-02],\n",
            "          [ 4.3511e-02, -2.6110e-01,  7.7879e-01,  ..., -5.3317e-01,\n",
            "           -4.6298e-01,  1.4049e-01],\n",
            "          [ 2.8785e-01, -6.6590e-01, -7.1256e-01,  ...,  6.6943e-01,\n",
            "           -1.3223e-01, -2.7596e-01],\n",
            "          [ 1.6076e-01, -1.0207e+00, -8.2697e-01,  ..., -1.4479e-02,\n",
            "            2.0910e-01,  8.3381e-01]],\n",
            "\n",
            "         [[-6.5020e-03,  9.3000e-03,  1.2400e-02,  ..., -1.3463e-03,\n",
            "           -2.6796e-02,  2.4005e-02],\n",
            "          [-4.2541e-01,  2.8131e-01, -7.1237e-01,  ...,  3.2777e-01,\n",
            "            2.5799e-01,  9.1277e-01],\n",
            "          [-9.0727e-01, -5.8112e-01, -9.1641e-01,  ...,  6.1913e-02,\n",
            "            7.2926e-01, -4.4645e-02],\n",
            "          [-2.1584e-01, -7.0632e-01,  3.2361e-01,  ..., -1.2718e+00,\n",
            "           -1.4493e+00, -3.2210e-01]],\n",
            "\n",
            "         [[ 4.9350e-02, -5.0358e-02,  1.2117e-02,  ..., -2.2806e-03,\n",
            "            2.2098e-02, -5.4698e-02],\n",
            "          [-3.7184e-01,  1.8355e+00,  5.0474e-01,  ...,  1.0830e+00,\n",
            "           -1.3266e-01, -1.1566e+00],\n",
            "          [ 1.9068e+00,  6.8058e-01, -3.0096e-01,  ...,  9.8832e-02,\n",
            "           -6.8062e-01,  7.2432e-02],\n",
            "          [-1.5413e+00,  2.8976e-01, -1.5093e+00,  ...,  2.3018e-01,\n",
            "           -1.2569e+00,  7.3134e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7501e-04, -1.5963e-02, -6.4565e-03,  ..., -8.2846e-03,\n",
            "           -1.8751e-02, -5.8902e-02],\n",
            "          [ 8.5277e-01,  3.4943e-01,  4.3258e-01,  ...,  5.2940e-01,\n",
            "           -1.6158e-01,  7.6588e-02],\n",
            "          [-6.2678e-01,  7.8272e-01, -3.4588e-01,  ..., -2.5181e-01,\n",
            "            9.6965e-01, -4.8926e-01],\n",
            "          [ 9.8891e-01, -2.8072e-01, -3.7897e-01,  ..., -1.7478e-01,\n",
            "           -2.2029e-01, -6.5556e-01]],\n",
            "\n",
            "         [[-2.9442e-01, -1.4525e-02, -5.5205e-04,  ..., -3.4645e-02,\n",
            "            1.3259e-02, -3.8834e-02],\n",
            "          [-8.7863e-01,  1.4818e-01, -2.2928e-02,  ...,  8.7287e-01,\n",
            "            4.4381e-01,  6.8204e-02],\n",
            "          [-1.0145e+00, -2.6782e-01,  1.0821e-01,  ...,  1.5391e+00,\n",
            "           -3.0619e-01, -4.2362e-02],\n",
            "          [ 7.6057e-01,  3.8729e-01, -1.2852e+00,  ...,  1.4513e+00,\n",
            "           -7.3135e-01,  8.6315e-01]],\n",
            "\n",
            "         [[ 3.1770e-02,  1.7892e-02,  2.4632e-02,  ...,  8.6995e-03,\n",
            "            8.2694e-03, -2.1142e-02],\n",
            "          [-1.0196e+00,  3.0224e-02, -3.5180e-01,  ..., -4.0792e-01,\n",
            "           -2.1419e+00, -2.6209e-01],\n",
            "          [ 2.1067e-01,  3.8108e-01, -1.3615e-01,  ..., -4.4213e-01,\n",
            "           -1.3498e+00, -4.0413e-02],\n",
            "          [-9.7609e-03,  3.3915e-01, -1.0430e+00,  ...,  6.3357e-01,\n",
            "           -2.0516e+00, -2.1790e-01]]]])), (tensor([[[[-1.0301e-02, -2.4163e-01, -5.2511e-01,  ...,  2.2826e-01,\n",
            "            4.5017e-01,  3.5501e-01],\n",
            "          [-5.5918e-01,  1.2994e+00, -3.3235e-01,  ...,  1.0347e+00,\n",
            "           -2.7429e-01, -6.5642e-02],\n",
            "          [-9.7736e-01,  4.8930e-01,  1.3744e+00,  ...,  8.6363e-01,\n",
            "           -4.0978e-01, -8.5547e-01],\n",
            "          [-1.9797e-01,  1.0862e+00,  6.5522e-01,  ...,  6.8693e-01,\n",
            "           -1.4681e+00,  8.8959e-01]],\n",
            "\n",
            "         [[-1.7390e-01, -2.3657e-02,  6.9402e-02,  ..., -8.8225e-03,\n",
            "           -1.0142e+00, -1.3008e-01],\n",
            "          [-8.6373e-01, -1.1510e-03,  8.3475e-02,  ...,  1.1696e+00,\n",
            "           -7.3199e-01,  1.4226e+00],\n",
            "          [-3.5039e-01, -4.3842e-01,  8.5943e-01,  ..., -9.9485e-01,\n",
            "           -1.5842e-01, -3.4699e-01],\n",
            "          [ 1.7753e-01, -3.7210e-01,  1.2111e+00,  ..., -1.6046e-01,\n",
            "           -1.0405e+00,  1.5732e+00]],\n",
            "\n",
            "         [[-9.9367e-01,  4.1060e-02,  4.7197e-01,  ..., -6.9384e-01,\n",
            "            4.0767e-01, -8.1606e-02],\n",
            "          [ 1.1084e+00, -1.0611e-02, -4.5176e-01,  ...,  7.5217e-01,\n",
            "           -9.6971e-01, -9.4983e-01],\n",
            "          [ 1.0173e+00,  1.5418e-01, -8.2486e-01,  ...,  7.9046e-01,\n",
            "            3.1478e-01, -1.2288e-01],\n",
            "          [ 1.7835e+00,  2.4385e+00,  2.1749e-02,  ...,  2.6675e+00,\n",
            "            1.8647e-01,  1.0470e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.4736e-01, -8.6950e-01, -3.3081e-01,  ..., -8.9743e-01,\n",
            "           -4.6136e-01,  6.0198e-01],\n",
            "          [-1.2778e-01, -1.4567e-01, -9.0353e-01,  ...,  7.7981e-02,\n",
            "            1.8806e-01, -9.0736e-01],\n",
            "          [ 5.6794e-01, -4.5663e-02,  7.9746e-02,  ...,  4.4562e-01,\n",
            "            1.1094e+00, -1.9625e+00],\n",
            "          [-7.6842e-01,  2.0359e+00, -3.2561e-01,  ..., -3.0604e-01,\n",
            "            5.0830e-01, -1.5945e+00]],\n",
            "\n",
            "         [[-7.5992e-01,  2.4114e+00,  3.5377e-01,  ...,  1.9402e-01,\n",
            "            1.9266e+00, -4.3384e-01],\n",
            "          [ 7.3690e-01, -1.8158e+00,  3.3521e-02,  ..., -1.0929e-01,\n",
            "           -2.7071e+00,  1.6838e+00],\n",
            "          [-2.2509e-01, -3.0866e+00, -1.9460e-01,  ...,  1.0243e+00,\n",
            "           -2.2304e+00,  1.8711e+00],\n",
            "          [ 3.6307e-01, -1.3832e+00,  1.4231e+00,  ..., -7.8819e-01,\n",
            "           -1.9420e+00,  8.8681e-01]],\n",
            "\n",
            "         [[-1.7871e+00, -2.8095e-01, -1.0364e+00,  ..., -4.1990e-01,\n",
            "            1.5128e-01,  2.2748e-01],\n",
            "          [ 1.7558e+00,  5.1133e-01,  4.4422e-01,  ...,  2.0829e-01,\n",
            "            1.5211e-02, -6.0282e-02],\n",
            "          [ 2.4523e+00,  1.0479e+00,  1.4126e+00,  ...,  1.2125e+00,\n",
            "           -7.4547e-01,  7.3674e-01],\n",
            "          [ 2.4502e+00,  4.7362e-01, -4.3496e-01,  ...,  4.1924e-01,\n",
            "           -1.2938e+00,  1.4549e-01]]]]), tensor([[[[-0.0362, -0.0264,  0.0066,  ...,  0.0508, -0.0104,  0.0337],\n",
            "          [-0.0242,  0.2976,  0.1059,  ...,  0.3469, -0.8739, -0.5928],\n",
            "          [-0.8575,  0.0519, -0.3175,  ..., -0.2026, -0.6570,  0.1984],\n",
            "          [-1.3781, -0.5577,  0.3127,  ..., -1.8135,  0.4403,  0.6416]],\n",
            "\n",
            "         [[ 0.0163,  0.0128, -0.0150,  ...,  0.0094,  0.0170,  0.0101],\n",
            "          [-0.9035,  0.5209,  0.8435,  ...,  1.0308, -0.4888,  0.8734],\n",
            "          [-0.9131, -0.8256, -1.7861,  ..., -0.0399, -0.0304, -0.8067],\n",
            "          [ 0.4524, -0.5768, -1.7663,  ..., -1.8430, -1.1425, -0.2187]],\n",
            "\n",
            "         [[-0.0294,  0.0166, -0.0222,  ...,  0.0078, -0.0058, -0.0085],\n",
            "          [-0.5630, -0.8018,  0.0084,  ..., -0.3208, -0.2265, -0.7723],\n",
            "          [-1.3104, -0.3370,  0.5642,  ...,  0.0566, -1.4171, -0.7562],\n",
            "          [ 0.5369,  2.0810,  0.7720,  ...,  1.6485,  0.1897, -0.0716]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0124,  0.0447,  0.0363,  ..., -0.0032,  0.0060, -0.0118],\n",
            "          [ 0.2051, -0.0391,  1.5519,  ..., -0.3041,  0.5073,  0.1738],\n",
            "          [-0.2842,  0.8398, -1.0647,  ..., -0.2844,  0.3361,  0.5741],\n",
            "          [ 0.5123, -0.5035,  1.1765,  ..., -1.4618,  1.6084,  0.1083]],\n",
            "\n",
            "         [[-0.0140, -0.0079, -0.0284,  ...,  0.0164, -0.0088, -0.0288],\n",
            "          [-0.4472,  0.0535, -0.3764,  ...,  0.1776,  0.0173,  0.2966],\n",
            "          [-0.4114, -0.1788, -1.3561,  ..., -0.3864, -0.2177, -0.2289],\n",
            "          [ 1.2757,  0.2195, -1.7911,  ..., -0.6213, -0.5040,  1.9244]],\n",
            "\n",
            "         [[-0.0034, -0.0126,  0.0230,  ...,  0.0080, -0.0125,  0.0098],\n",
            "          [ 0.6718, -0.0728, -0.8827,  ...,  2.5025, -0.7522, -0.1317],\n",
            "          [ 0.4813, -0.3173, -1.0557,  ...,  1.5898,  0.8905,  0.6451],\n",
            "          [-1.0148, -1.9379, -0.6296,  ..., -0.7641,  1.1638, -1.3634]]]])), (tensor([[[[-1.6697, -0.4329, -0.4083,  ...,  0.2911,  0.3874, -0.4542],\n",
            "          [-0.4606,  0.9902, -0.9397,  ...,  0.8185, -1.2474,  0.1127],\n",
            "          [-0.1556,  0.3529, -0.1843,  ...,  0.3538, -0.0965,  0.5455],\n",
            "          [ 1.0229,  1.7053, -0.6457,  ...,  0.9076, -0.7099,  0.2296]],\n",
            "\n",
            "         [[ 0.0628, -0.1471,  1.9642,  ...,  0.2374,  0.1009, -0.2088],\n",
            "          [ 0.4111, -0.3496, -0.3683,  ..., -0.2328, -0.0694, -0.5711],\n",
            "          [-0.4323,  0.1323,  0.3703,  ..., -1.0531, -0.4732, -0.4800],\n",
            "          [ 0.7813, -1.0260,  1.0960,  ...,  0.1283,  0.0395,  0.5384]],\n",
            "\n",
            "         [[ 0.0345,  0.8826,  0.4935,  ..., -0.5864,  0.3096, -0.0784],\n",
            "          [-0.2844, -0.7483,  0.0709,  ...,  1.3326,  0.0445, -0.9665],\n",
            "          [-0.0077, -1.2108, -0.2264,  ...,  1.1867, -0.1942, -0.4869],\n",
            "          [-0.2716, -1.2659, -0.6935,  ...,  1.6245, -0.3856, -0.0550]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.6339,  0.9521, -0.9683,  ..., -0.7001,  0.6110,  0.8349],\n",
            "          [-0.6914,  0.1875, -0.6861,  ..., -0.5064, -0.8844, -0.0919],\n",
            "          [-0.6521,  0.5949, -0.8196,  ...,  0.1243, -0.8979, -0.8724],\n",
            "          [ 0.0337,  0.2810,  0.2849,  ...,  0.8251,  0.2104, -1.5536]],\n",
            "\n",
            "         [[-0.3576,  0.3938,  0.7700,  ...,  0.5429, -0.1884, -0.2902],\n",
            "          [-0.4593,  1.1598,  0.5252,  ...,  0.9137, -1.1783, -0.6765],\n",
            "          [-0.6187,  0.3244, -0.7538,  ...,  0.7527, -1.1950,  0.4350],\n",
            "          [-0.8651, -0.8981,  2.2752,  ..., -0.5582,  0.2130,  0.5872]],\n",
            "\n",
            "         [[-0.7150, -0.1650,  0.3624,  ...,  0.0413,  0.0530,  0.0827],\n",
            "          [-0.3698, -0.9550,  1.8217,  ..., -0.2801, -0.0325,  1.2502],\n",
            "          [ 0.0539,  0.5489,  0.2025,  ..., -0.4946,  0.9027,  0.5349],\n",
            "          [ 0.8596,  0.0854,  0.4756,  ..., -0.7509, -0.3263,  0.9315]]]]), tensor([[[[-3.5634e-02, -3.5621e-02, -3.9245e-02,  ..., -6.8534e-03,\n",
            "            6.8842e-03,  3.6135e-03],\n",
            "          [-4.2485e-01, -1.3104e-01,  1.3052e+00,  ...,  1.1735e+00,\n",
            "           -1.8384e+00,  1.1700e+00],\n",
            "          [ 5.5738e-01,  2.2042e-01,  7.5813e-01,  ..., -9.2292e-02,\n",
            "           -1.2364e+00,  1.0330e+00],\n",
            "          [ 7.7231e-01, -1.2409e+00,  8.7065e-01,  ...,  3.6015e-01,\n",
            "           -2.2860e+00, -1.3397e+00]],\n",
            "\n",
            "         [[-2.6226e-02,  5.7698e-03,  9.4467e-04,  ..., -2.0191e-02,\n",
            "            2.7733e-02, -4.3203e-02],\n",
            "          [-2.3383e-01, -5.5108e-01,  5.2210e-01,  ...,  4.2042e-01,\n",
            "           -7.7676e-01, -4.7004e-02],\n",
            "          [-9.8451e-01, -1.7732e-01,  8.3193e-01,  ..., -4.0907e-01,\n",
            "            6.2886e-01, -4.3238e-01],\n",
            "          [ 5.3134e-01,  1.3510e+00,  1.1318e+00,  ...,  8.3644e-01,\n",
            "            1.5318e-01, -1.6918e-01]],\n",
            "\n",
            "         [[ 7.0211e-02, -4.2840e-03,  2.3482e-02,  ..., -8.0910e-02,\n",
            "           -8.5117e-03, -1.7357e-03],\n",
            "          [-5.2141e-01, -4.0950e-02, -6.5530e-01,  ..., -3.5748e-01,\n",
            "            5.3280e-01,  8.9260e-01],\n",
            "          [ 1.8243e-01, -2.8913e-01,  2.3793e-01,  ..., -8.1981e-01,\n",
            "            3.2152e-01,  1.1663e+00],\n",
            "          [-1.4899e+00,  1.8544e+00,  4.7113e-01,  ...,  3.8623e-02,\n",
            "            9.3175e-01,  5.0029e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6146e-02,  2.7228e-03, -1.0135e-01,  ...,  1.0337e-03,\n",
            "           -9.9388e-03, -2.0434e-02],\n",
            "          [ 4.9008e-01,  8.8021e-01, -7.3225e-01,  ...,  6.8277e-01,\n",
            "            1.1027e+00,  3.7396e-01],\n",
            "          [-1.1389e+00,  7.2231e-01, -1.2210e+00,  ...,  1.5694e+00,\n",
            "           -4.6706e-01,  3.8230e-01],\n",
            "          [-4.9176e-01,  1.5549e+00, -5.3695e-01,  ...,  2.4713e+00,\n",
            "            1.2343e+00, -7.5238e-01]],\n",
            "\n",
            "         [[-9.1498e-03, -2.0397e-03, -2.1485e-02,  ...,  3.2534e-02,\n",
            "            1.0582e-02,  4.7933e-04],\n",
            "          [ 5.8697e-01, -5.4234e-02, -8.4877e-01,  ..., -1.8337e-01,\n",
            "           -1.8932e-01, -1.7225e-01],\n",
            "          [ 4.6650e-01,  1.2675e-01,  4.8932e-01,  ...,  5.9822e-01,\n",
            "            2.1967e-01,  7.0705e-01],\n",
            "          [-6.4229e-01,  3.8886e-01,  5.0034e-02,  ...,  1.1351e+00,\n",
            "           -1.0397e+00,  5.8712e-01]],\n",
            "\n",
            "         [[-4.5735e-02, -3.4272e-02,  3.0896e-02,  ..., -1.0849e-01,\n",
            "           -4.2277e-02,  6.7413e-03],\n",
            "          [-4.6882e-01,  7.4865e-01,  3.6994e-01,  ..., -9.6507e-01,\n",
            "           -5.3878e-01, -2.1390e-01],\n",
            "          [ 2.3016e-01, -4.6651e-01,  3.3048e-01,  ..., -8.7835e-01,\n",
            "           -9.1112e-01,  5.9535e-01],\n",
            "          [-1.3792e-01,  2.5761e+00,  2.5628e+00,  ..., -1.6041e+00,\n",
            "           -1.2105e-01,  1.1975e+00]]]]))), hidden_states=None, attentions=None, cross_attentions=None)\n",
            "Outputs dimensions: torch.Size([1, 4, 768])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"Outputs:\\n\", outputs)\n",
        "print(\"Outputs dimensions:\", outputs[0].shape) # shape: (batch_size, num_tokens, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
      "metadata": {
        "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef1f31d-3554-40ff-e3e1-b440bb8c93c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last output token: tensor([[ 8.1171e-01, -3.5430e-01, -1.2459e+00, -1.5412e-01,  6.5543e-01,\n",
            "         -8.8496e-02,  1.4950e+00, -1.5117e-01, -3.9650e-01,  3.4764e-02,\n",
            "          1.0481e+00, -1.0955e-01,  1.9246e-01, -2.0562e-01,  1.2523e-01,\n",
            "          2.3355e-01, -1.4321e-01,  7.6850e-02, -7.1275e-02, -4.1272e-01,\n",
            "          9.7501e-02, -3.9924e-01, -6.5992e-01, -6.4883e-01,  1.3287e-01,\n",
            "         -4.6481e-01, -1.3318e-02, -2.1985e-02, -2.0715e-01,  1.0378e-01,\n",
            "          3.7294e-01, -6.2228e-01, -2.8820e-01, -3.8752e-01, -9.8934e-02,\n",
            "          9.6872e-02,  2.3733e+01,  4.7451e-01,  2.9476e-01,  7.1560e-01,\n",
            "          4.6157e-01, -3.2951e-01,  5.0652e-01, -3.1840e-01, -2.9630e-01,\n",
            "         -1.5837e-01,  2.5641e-01, -4.4798e-01, -7.5088e-01, -3.7023e-01,\n",
            "          2.9352e-01,  6.9610e-01,  2.3215e-01,  3.9491e-01,  9.9512e-02,\n",
            "          1.4651e-01, -1.9988e-01, -1.3202e-01,  3.7080e-01, -2.0201e-01,\n",
            "          3.2545e-02,  1.9826e-02,  1.1745e-01, -3.5853e-01, -1.2417e+00,\n",
            "         -5.5155e-01, -3.2067e-01,  1.6341e-01, -1.3040e-01, -1.4061e-01,\n",
            "          2.5700e-01,  7.1813e-01,  1.2195e-01, -4.9571e-01, -5.7584e-02,\n",
            "          2.8240e-01,  2.5743e-02,  3.1965e-01,  6.4849e-01,  1.1292e-02,\n",
            "         -9.4396e-01,  3.5986e-01, -1.1357e-01, -1.8319e-01,  1.0276e-01,\n",
            "          5.5909e-01, -6.3767e-01, -1.1511e+00,  2.2421e-01,  2.6450e-01,\n",
            "         -1.4862e-01, -3.3969e-01, -5.0080e-01,  2.5670e-01,  6.9984e-02,\n",
            "          2.5061e-01, -2.6019e-01, -4.1035e-01,  6.1707e-01,  3.1258e-01,\n",
            "         -1.3077e-01,  4.8080e-01,  1.8219e-01,  2.6708e-01, -1.7028e-01,\n",
            "         -1.2521e-01, -2.4971e-01, -8.9243e-01,  2.0863e-01, -1.0394e+00,\n",
            "         -2.1881e-01, -1.7681e-01, -1.0386e+00,  2.2660e-01,  3.4991e-01,\n",
            "          3.6459e-01, -9.2044e-02, -3.4682e-01, -1.6926e-01, -3.0416e-02,\n",
            "         -1.8719e-01,  7.0132e-02,  3.6376e-01,  1.5033e-02,  2.2070e-01,\n",
            "          4.0839e-01, -5.9286e-02, -5.8455e-01,  2.3347e-02,  1.5418e-01,\n",
            "          5.5947e-01, -3.4229e-02,  1.8481e-01, -1.7039e-01, -4.5518e-01,\n",
            "         -1.0221e-01, -8.6825e-02,  5.8499e-02,  6.1266e-01, -5.5307e-01,\n",
            "         -2.0891e-01,  1.7271e-01, -1.8476e+00,  2.3224e-01,  4.5433e-01,\n",
            "          7.5351e-01,  1.0333e-03, -9.4882e-02,  3.4250e-01,  5.0115e-01,\n",
            "         -1.7560e-01,  3.7026e-01,  6.1906e-02, -7.4743e-01, -1.0672e-01,\n",
            "          5.1026e-01,  3.5925e-01, -4.4405e-01,  3.1124e-01,  2.3492e-01,\n",
            "          1.6006e+00,  7.9012e-02,  2.4688e-01,  1.7266e-01, -1.2203e-02,\n",
            "         -3.9443e-01,  5.4179e-02, -1.7997e+00,  3.8432e-01, -2.6807e-01,\n",
            "          1.1388e-01, -5.2447e-01, -3.8313e-01, -6.7236e-02,  4.7824e-01,\n",
            "         -2.8874e-01,  3.4904e-01, -3.1511e-01,  8.2923e-02,  4.6665e-01,\n",
            "         -3.3726e-01, -2.9840e-01,  2.0933e-02, -4.4998e-02,  8.8293e-01,\n",
            "          6.2541e-01,  3.5215e-01,  6.0330e-01, -1.3655e-01,  3.1970e-01,\n",
            "         -8.6658e-03, -1.6428e-01, -3.2128e-01,  2.2079e-01,  2.7911e-02,\n",
            "          1.9289e-01,  1.4361e-01, -5.8546e-01,  1.9859e-01, -5.6227e-01,\n",
            "         -4.8999e-01, -8.4167e-02, -1.1879e-01, -2.8925e-01,  1.2029e-01,\n",
            "          2.3420e-01,  2.0869e-01,  2.7122e-01, -2.7453e-01, -2.0518e-02,\n",
            "         -7.9163e-03, -3.5472e-01,  5.5176e-02,  5.9492e-01, -5.6552e-02,\n",
            "          1.5109e-01, -5.7487e-03,  1.9617e-01,  1.1072e-01, -2.0136e-01,\n",
            "         -2.4719e-01,  3.4411e-01, -1.0802e-01,  2.4810e-01,  1.1916e+00,\n",
            "         -2.3037e-01, -2.5634e-01, -4.7901e-01,  7.6976e-01,  1.5480e-01,\n",
            "          1.5451e-01, -1.1365e-01,  8.2838e-02,  2.9075e-01, -1.4983e-01,\n",
            "         -5.9718e-01, -2.1023e-01,  8.8445e-03,  6.9391e-03,  2.6892e-01,\n",
            "          6.1433e-01,  3.5045e-01,  7.6351e-03,  2.6588e-01,  2.7894e-01,\n",
            "         -1.4685e-01, -1.8848e-02,  2.2040e-01, -8.6764e-02, -4.3312e-01,\n",
            "         -6.4104e-02,  4.9883e-01, -1.2741e-01, -3.3203e-01, -6.5275e-01,\n",
            "          1.1994e+00,  5.4630e-01,  4.2652e-01,  5.5595e-01,  1.1600e+00,\n",
            "         -3.6311e-01,  1.8716e-01,  2.5228e-01, -1.9311e-01, -6.1423e-01,\n",
            "          1.2555e-01, -1.1262e+00, -1.5838e-01, -2.3451e-01,  2.1928e-01,\n",
            "          9.3345e-01,  3.4317e+00,  5.7633e-01,  2.4344e-01,  4.2100e-01,\n",
            "          1.9574e-01, -2.4276e-01, -2.1456e-01, -4.2052e-02, -1.3998e-01,\n",
            "          7.4656e-01, -1.8585e-01,  5.6937e-01,  4.0200e-01, -1.9481e-01,\n",
            "          5.1046e-01,  1.2729e-01,  1.1902e-01,  5.3524e-01,  2.5111e-01,\n",
            "          2.1577e-02, -6.7461e-01, -4.3274e-01, -3.3436e-02,  3.5018e-01,\n",
            "         -3.8154e-01, -5.5039e-02, -5.0031e-02, -4.5807e-02,  3.4340e-01,\n",
            "          1.2211e-02, -2.9043e-03,  7.7623e-01,  4.4257e-02,  5.7468e-02,\n",
            "          1.7613e-01,  6.3451e-01,  3.7773e-01, -1.6968e-01, -1.3328e-01,\n",
            "         -1.3365e-01, -7.1278e-01, -5.0193e-02, -1.9026e-01, -8.0889e+00,\n",
            "         -5.7891e-01, -3.1810e-01,  5.8987e-02,  4.0779e-01,  3.5803e-01,\n",
            "         -4.2558e-01, -1.2592e-01,  5.8745e-01,  9.5490e-02, -8.5763e-02,\n",
            "          3.0700e-01,  4.4270e-01, -2.4576e-01,  2.9248e-01, -3.6933e-01,\n",
            "         -1.9499e-01,  8.6712e-02, -3.1156e-02, -1.4182e-01, -3.1727e-01,\n",
            "         -7.0798e-01, -2.0137e-01, -4.6612e-01, -4.2259e-02, -1.0363e-02,\n",
            "          6.2209e-01,  1.8283e-01,  5.0998e-01, -7.9053e-01,  3.9137e-01,\n",
            "         -3.4756e-01,  6.7670e-02,  3.4123e-01,  5.8794e-01, -2.6445e-01,\n",
            "          7.7021e-02,  5.9460e-01, -2.1993e-01, -5.7144e-02,  1.4296e-01,\n",
            "         -1.3723e-01,  6.6611e-01,  6.9096e-03,  2.9981e-01, -6.8292e-02,\n",
            "          3.1657e-01,  1.2797e+00, -1.2981e-01, -1.6868e-01,  2.3507e-01,\n",
            "         -1.5848e+00, -4.2476e-01,  4.8298e-01,  2.0162e-01,  2.5346e-01,\n",
            "          6.7117e-01,  5.8334e-02, -1.9527e-01, -1.2309e+00, -9.1466e+00,\n",
            "         -6.0898e-01, -2.2071e-01,  1.6403e+00,  1.4790e-02,  5.7656e-01,\n",
            "          2.1510e-01,  7.7305e-02,  2.3636e-01,  1.8931e-01, -9.7775e-01,\n",
            "         -7.3559e-01, -1.9771e-01, -4.7421e-02, -7.2411e-01, -6.8477e-02,\n",
            "         -6.4916e-01,  2.6351e-01,  6.6972e-01,  5.3737e-02, -1.0574e-01,\n",
            "          3.7378e-01, -6.1793e-01,  6.2811e-01,  4.7547e-01, -2.6363e-01,\n",
            "          3.2086e-01, -7.6478e-01,  3.3156e-01, -1.6952e-01, -9.8409e-02,\n",
            "         -3.6053e-01,  1.4401e-01, -4.5991e-02,  7.4274e-01, -3.5688e-01,\n",
            "         -7.7189e-01,  2.8664e-01,  4.0953e-01, -2.4587e-01, -2.7537e-01,\n",
            "         -5.1797e-01,  2.6961e-01, -7.3511e-01, -7.7656e-01, -4.5205e-02,\n",
            "         -3.0088e-01, -6.2871e-02,  5.1699e-01,  1.1393e-01, -1.6900e-01,\n",
            "         -4.3291e-01, -2.1198e-01, -9.2078e-02,  3.4083e-01, -4.3260e-02,\n",
            "          4.2332e+01,  6.3825e-02, -6.4205e-01, -2.8937e-01,  1.7286e-01,\n",
            "          8.5047e-01,  8.3952e-02,  1.1629e-01, -4.0500e-01,  3.7705e-01,\n",
            "          2.0108e-01, -5.5767e-02,  2.6937e+00, -2.3142e-01,  2.9068e-02,\n",
            "          1.7231e-01, -1.9404e-02,  1.0998e+00, -2.8563e-01, -3.2154e-01,\n",
            "          9.2253e-02,  1.2485e-01,  1.5601e-02, -8.8682e-01, -4.6627e-02,\n",
            "          1.4942e+00, -6.6888e-02, -2.8171e-01,  2.8167e-01,  5.4988e-01,\n",
            "          2.1596e-01,  1.7277e-01,  9.3709e-02, -6.8653e-02, -2.2395e-02,\n",
            "         -5.2223e-01,  1.4533e-01, -5.2998e-01,  4.0805e-02, -3.7698e-02,\n",
            "         -2.2625e-01,  2.8640e-01, -4.8492e-01,  9.9452e-02,  1.8357e-01,\n",
            "          1.6634e-01,  4.8450e-02, -3.0177e-01,  2.2243e-01, -3.4327e+00,\n",
            "         -9.9043e-01,  1.2441e+00, -7.0193e-01,  1.9585e-01, -4.6445e-01,\n",
            "          9.4785e-02, -5.1225e-03, -6.8327e-02,  3.5285e-01, -7.9518e-01,\n",
            "          5.9648e-02,  7.4716e-01,  2.3483e-02,  4.7398e-02, -2.6773e-01,\n",
            "          3.1646e-01,  1.0804e+02, -1.8795e-01,  3.3548e-01,  2.4461e-02,\n",
            "         -1.8940e-01, -4.4943e-01,  5.8933e-01,  6.3784e-01,  8.1989e-01,\n",
            "         -5.1706e-01,  6.2210e-01,  1.2076e-01, -3.5998e-01,  7.9764e-02,\n",
            "         -9.4337e-02, -4.1005e-01, -1.3066e-01,  1.9731e-01, -3.2383e-01,\n",
            "          1.1368e-01, -1.3421e-01,  6.1225e-01,  1.7570e-01,  2.1807e-01,\n",
            "          2.9893e-01, -1.3118e-01,  1.1659e-01,  1.4867e-01, -7.4790e-02,\n",
            "          3.0397e-01, -2.3781e-01, -8.3477e-01, -5.4575e-01,  2.6837e-01,\n",
            "          1.5357e-02,  9.6888e-01, -3.3656e-02, -1.0834e-01, -6.0470e-01,\n",
            "         -8.0446e-01, -5.0810e-01,  2.7413e-01, -7.6467e-01,  2.8158e-01,\n",
            "          6.0294e-01,  9.6721e-02, -6.0886e-02, -1.4309e+00, -8.7365e-01,\n",
            "          7.7903e-01,  4.6696e-01, -2.6696e-01, -2.4325e-01, -2.1346e-01,\n",
            "          5.2950e-01,  3.0976e-01,  2.4491e-01,  9.3851e-02, -4.4197e-01,\n",
            "         -3.4053e-01, -1.0732e-01,  2.9144e-01, -1.9142e-01, -4.0949e-02,\n",
            "         -5.5494e-01, -6.2924e-01,  1.2972e-01, -2.4553e-02,  1.0143e-01,\n",
            "          5.5531e-01, -4.0219e-02, -3.0682e-01,  7.1170e-03, -7.2833e-01,\n",
            "          2.6393e-01,  5.2077e-01, -4.4424e-01, -2.7521e-01, -2.3209e-01,\n",
            "          6.6134e-01, -2.9558e-01, -7.0701e-02, -1.1795e-01,  3.2573e-01,\n",
            "         -2.2242e-01, -4.7107e-01, -3.5536e-01,  4.2782e-01,  2.3435e-01,\n",
            "          1.9604e-01,  1.6251e-01, -2.4970e-01,  4.0917e-01,  8.8555e-02,\n",
            "         -2.6055e-01,  3.6644e-01,  7.4925e-01,  1.4164e-01,  2.3376e-01,\n",
            "          3.4216e-02,  3.9384e-01,  2.9315e-01, -1.4927e-01, -1.2609e-01,\n",
            "         -1.7529e-01,  4.7211e-02,  6.8414e-02,  1.7908e-01,  3.5691e-01,\n",
            "         -2.3093e-01, -3.8017e-01, -3.9281e-01,  3.4289e-01,  6.1753e-01,\n",
            "         -2.2939e-02,  2.1186e-01, -6.7467e-01,  1.6375e-01, -2.8810e-01,\n",
            "          7.8209e-02, -2.9876e-01, -9.0364e-01, -1.7450e-01,  5.1987e-01,\n",
            "          1.6733e-01, -5.3053e-01, -1.2219e-01,  8.3852e-01,  3.3200e-01,\n",
            "          1.1438e-01, -3.6628e-01, -1.6653e+00, -8.3046e-02,  1.1202e-02,\n",
            "         -7.7555e-02, -5.2142e-02, -4.8560e-01,  5.8198e-01,  1.9448e-01,\n",
            "          5.7112e-01, -2.5538e-01, -4.2717e-01, -1.9866e-01,  5.5783e-01,\n",
            "         -7.9136e-01,  4.3354e-02,  1.6795e-01, -4.3025e-01, -6.8138e-01,\n",
            "         -3.4974e-01,  7.3349e-01,  1.3504e-01, -1.6676e-01,  4.6968e-01,\n",
            "          3.1157e-01,  9.9607e-01,  2.7386e-01,  2.2650e-01, -8.4876e-02,\n",
            "         -1.1831e+00, -9.7829e-02,  6.2942e-01,  1.0533e-01, -6.5144e-02,\n",
            "          1.3570e-01,  1.2599e-01, -6.8180e-01, -7.2288e-03,  4.7522e-02,\n",
            "          1.1960e-01,  7.6187e-04, -6.4048e-01,  9.4008e-01, -9.2595e-02,\n",
            "         -5.2484e-01,  2.0543e-02, -2.6047e-01, -3.0511e-01, -4.0732e-01,\n",
            "          3.9632e-02, -2.2947e-01,  3.3518e-01,  1.5559e-01,  3.5877e-01,\n",
            "         -2.3371e-01, -6.9378e-01,  2.6370e-01,  3.0321e-01,  1.0833e-01,\n",
            "         -8.8312e-02, -3.3288e-01,  3.1276e-01,  7.4066e-02, -2.6724e-01,\n",
            "          5.0645e-01,  5.7855e-01, -3.9962e-01, -8.0169e-02, -2.8884e-01,\n",
            "          2.5415e-01, -4.4513e-02, -4.8387e-01,  8.0624e-01,  4.0012e-02,\n",
            "         -3.2106e-01,  9.8946e-02,  8.3356e-02, -2.3013e-01, -2.1409e-03,\n",
            "          1.9917e-01, -9.8628e-03,  1.1165e-01,  3.5364e-01,  1.3509e-02,\n",
            "          9.6097e-02,  4.7209e-01, -2.0265e-01,  1.6125e-01,  2.0229e-01,\n",
            "          3.5599e-01, -6.1129e-01, -6.2789e-02,  6.7585e-01,  2.0235e-01,\n",
            "          2.6816e-01,  1.3836e-01,  1.1523e-01, -7.1705e-02,  2.8287e+00,\n",
            "         -2.5589e-01,  7.1954e-01, -3.6350e-02, -4.1786e-01, -2.3712e-01,\n",
            "          1.0830e-01,  2.7474e-02,  8.1912e-02,  1.2150e-01, -2.2086e-01,\n",
            "          5.6763e-01, -4.5071e-02,  2.8122e-01, -6.4486e-02, -3.1439e-03,\n",
            "          2.7732e-01, -4.4334e-01,  8.0270e-02,  3.1909e-01,  1.2324e-01,\n",
            "         -8.6192e-02, -7.0428e-01, -1.8830e-01, -2.4880e-01,  7.1119e-02,\n",
            "          1.8555e-01, -4.1439e-01,  1.4030e-01,  1.0413e-01,  5.2858e-01,\n",
            "         -8.3350e-02, -8.7420e-01, -2.3422e-02, -2.8426e-03,  6.1916e-01,\n",
            "          1.8507e-01,  3.4857e-01,  2.0610e+00,  2.7513e-01,  7.2665e-02,\n",
            "          2.5709e-01,  3.0962e-01,  1.9151e-01]])\n"
          ]
        }
      ],
      "source": [
        "print(\"Last output token:\", outputs[0][:, -1, :])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
      "metadata": {
        "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[0][:, -1, :]  # Logits of last output token\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
      "metadata": {
        "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
      },
      "outputs": [],
      "source": [
        "# Same as in chapter 5\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # Reduce the number of batches to match the total number of batches in the data loader\n",
        "        # if num_batches exceeds the number of batches in the data loader\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
      "metadata": {
        "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1f95a1-046e-4f50-d406-ae936e83f5f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 64.729\n",
            "Validation loss: 62.903\n",
            "Test loss: 64.478\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device) # no assignment model = model.to(device) necessary for nn.Module classes\n",
        "\n",
        "torch.manual_seed(123) # For reproducibility due to the shuffling in the training data loader\n",
        "\n",
        "with torch.no_grad(): # Disable gradient tracking for efficiency because we are not training, yet\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"Training loss: {train_loss:.3f}\")\n",
        "print(f\"Validation loss: {val_loss:.3f}\")\n",
        "print(f\"Test loss: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ce5b12-84cd-488c-8ea7-4cef5b2d947e",
      "metadata": {
        "id": "64ce5b12-84cd-488c-8ea7-4cef5b2d947e"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad() # Disable gradient tracking for efficiency\n",
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "            logits = model(input_batch)[0][:, -1, :]  # Logits of last output token\n",
        "            # print(logits)\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2160418f-988b-40f3-bce8-e431021e97dc",
      "metadata": {
        "id": "2160418f-988b-40f3-bce8-e431021e97dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b80b88da-1fa1-4500-e4e7-252710089c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 0.00%\n",
            "Validation accuracy: 0.00%\n",
            "Test accuracy: 0.00%\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Csbr60to50FL",
      "metadata": {
        "id": "Csbr60to50FL"
      },
      "outputs": [],
      "source": [
        "# Overall the same as `train_model_simple` in chapter 5\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous epoch\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            examples_seen += input_batch.shape[0] # New: track examples instead of tokens\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Calculate accuracy after each epoch\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"Training accuracy: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
      "metadata": {
        "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
      },
      "outputs": [],
      "source": [
        "# Same as chapter 5\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X7kU3aAj7vTJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7kU3aAj7vTJ",
        "outputId": "c463a1bf-ccc5-43ad-eb97-6a8546c9bc6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 63.346, Val loss 61.306\n",
            "Ep 1 (Step 000050): Train loss 10.792, Val loss 10.778\n",
            "Ep 1 (Step 000100): Train loss 6.699, Val loss 6.822\n",
            "Ep 1 (Step 000150): Train loss 6.033, Val loss 6.114\n",
            "Ep 1 (Step 000200): Train loss 5.539, Val loss 5.613\n",
            "Ep 1 (Step 000250): Train loss 4.643, Val loss 4.746\n",
            "Ep 1 (Step 000300): Train loss 2.825, Val loss 3.231\n",
            "Ep 1 (Step 000350): Train loss 1.461, Val loss 1.650\n",
            "Ep 1 (Step 000400): Train loss 0.714, Val loss 0.874\n",
            "Ep 1 (Step 000450): Train loss 0.544, Val loss 0.661\n",
            "Ep 1 (Step 000500): Train loss 0.471, Val loss 0.566\n",
            "Ep 1 (Step 000550): Train loss 0.409, Val loss 0.554\n",
            "Ep 1 (Step 000600): Train loss 0.403, Val loss 0.520\n",
            "Training accuracy: 90.00% | Validation accuracy: 75.00%\n",
            "Ep 2 (Step 000650): Train loss 0.355, Val loss 0.615\n",
            "Ep 2 (Step 000700): Train loss 0.614, Val loss 0.545\n",
            "Ep 2 (Step 000750): Train loss 0.372, Val loss 0.539\n",
            "Ep 2 (Step 000800): Train loss 0.524, Val loss 0.564\n",
            "Ep 2 (Step 000850): Train loss 0.545, Val loss 0.531\n",
            "Ep 2 (Step 000900): Train loss 0.422, Val loss 0.503\n",
            "Ep 2 (Step 000950): Train loss 0.589, Val loss 0.522\n",
            "Ep 2 (Step 001000): Train loss 0.489, Val loss 0.529\n",
            "Ep 2 (Step 001050): Train loss 0.421, Val loss 0.521\n",
            "Ep 2 (Step 001100): Train loss 0.290, Val loss 0.498\n",
            "Ep 2 (Step 001150): Train loss 0.425, Val loss 0.496\n",
            "Ep 2 (Step 001200): Train loss 0.430, Val loss 0.541\n",
            "Ep 2 (Step 001250): Train loss 0.462, Val loss 0.479\n",
            "Training accuracy: 82.50% | Validation accuracy: 75.00%\n",
            "Ep 3 (Step 001300): Train loss 0.484, Val loss 0.536\n",
            "Ep 3 (Step 001350): Train loss 0.390, Val loss 0.503\n",
            "Ep 3 (Step 001400): Train loss 0.573, Val loss 0.487\n",
            "Ep 3 (Step 001450): Train loss 0.576, Val loss 0.465\n",
            "Ep 3 (Step 001500): Train loss 0.472, Val loss 0.462\n",
            "Ep 3 (Step 001550): Train loss 0.523, Val loss 0.527\n",
            "Ep 3 (Step 001600): Train loss 0.441, Val loss 0.467\n",
            "Ep 3 (Step 001650): Train loss 0.552, Val loss 0.510\n",
            "Ep 3 (Step 001700): Train loss 0.264, Val loss 0.450\n",
            "Ep 3 (Step 001750): Train loss 0.364, Val loss 0.473\n",
            "Ep 3 (Step 001800): Train loss 0.473, Val loss 0.552\n",
            "Ep 3 (Step 001850): Train loss 0.437, Val loss 0.478\n",
            "Ep 3 (Step 001900): Train loss 0.501, Val loss 0.633\n",
            "Training accuracy: 77.50% | Validation accuracy: 80.00%\n",
            "Ep 4 (Step 001950): Train loss 0.525, Val loss 0.480\n",
            "Ep 4 (Step 002000): Train loss 0.411, Val loss 0.519\n",
            "Ep 4 (Step 002050): Train loss 0.524, Val loss 0.452\n",
            "Ep 4 (Step 002100): Train loss 0.290, Val loss 0.563\n",
            "Ep 4 (Step 002150): Train loss 0.495, Val loss 0.537\n",
            "Ep 4 (Step 002200): Train loss 0.444, Val loss 0.436\n",
            "Ep 4 (Step 002250): Train loss 0.322, Val loss 0.427\n",
            "Ep 4 (Step 002300): Train loss 0.504, Val loss 0.450\n",
            "Ep 4 (Step 002350): Train loss 0.393, Val loss 0.463\n",
            "Ep 4 (Step 002400): Train loss 0.370, Val loss 0.462\n",
            "Ep 4 (Step 002450): Train loss 0.476, Val loss 0.415\n",
            "Ep 4 (Step 002500): Train loss 0.246, Val loss 0.444\n",
            "Ep 4 (Step 002550): Train loss 0.330, Val loss 0.448\n",
            "Training accuracy: 85.00% | Validation accuracy: 80.00%\n",
            "Ep 5 (Step 002600): Train loss 0.424, Val loss 0.410\n",
            "Ep 5 (Step 002650): Train loss 0.326, Val loss 0.479\n",
            "Ep 5 (Step 002700): Train loss 0.306, Val loss 0.467\n",
            "Ep 5 (Step 002750): Train loss 0.362, Val loss 0.412\n",
            "Ep 5 (Step 002800): Train loss 0.458, Val loss 0.473\n",
            "Ep 5 (Step 002850): Train loss 0.450, Val loss 0.441\n",
            "Ep 5 (Step 002900): Train loss 0.421, Val loss 0.449\n",
            "Ep 5 (Step 002950): Train loss 0.341, Val loss 0.424\n",
            "Ep 5 (Step 003000): Train loss 0.509, Val loss 0.475\n",
            "Ep 5 (Step 003050): Train loss 0.462, Val loss 0.456\n",
            "Ep 5 (Step 003100): Train loss 0.720, Val loss 0.514\n",
            "Ep 5 (Step 003150): Train loss 0.382, Val loss 0.469\n",
            "Ep 5 (Step 003200): Train loss 0.540, Val loss 0.466\n",
            "Training accuracy: 82.50% | Validation accuracy: 77.50%\n",
            "Training completed in 6.05 minutes.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cURgnDqdCeka",
      "metadata": {
        "id": "cURgnDqdCeka"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # Plot training and validation loss against epochs\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # Create a second x-axis for tokens seen\n",
        "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # Adjust layout to make room\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OIqRt466DiGk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "OIqRt466DiGk",
        "outputId": "5d7f3fbd-0987-4e63-c295-140ea35839c6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UHWaJFrjY0zW",
      "metadata": {
        "id": "UHWaJFrjY0zW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51864b15-a17b-45f1-b0b5-c12feb040951"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training accuracy: 78.16%\n",
            "Validation accuracy: 79.49%\n",
            "Test accuracy: 77.71%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"Training accuracy: {train_accuracy*100:.2f}%\")\n",
        "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
        "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aHdn6xvL-IW5",
      "metadata": {
        "id": "aHdn6xvL-IW5"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # Prepare inputs to the model\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = 1000\n",
        "\n",
        "    # Truncate sequences if they too long\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "\n",
        "    # Pad sequences to the longest sequence\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # add batch dimension\n",
        "\n",
        "    # Model inference\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[0][:, -1, :]  # Logits of the last output token\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # Return the classified result\n",
        "    return \"Positive\" if predicted_label == 1 else \"Negative\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "apU_pf51AWSV",
      "metadata": {
        "id": "apU_pf51AWSV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b305c11-0d0a-44b9-a49e-8b3343666276"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(text_1, model, tokenizer, device, max_length=train_dataset.max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1g5VTOo_Ajs5",
      "metadata": {
        "id": "1g5VTOo_Ajs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ab71713-3b0d-4951-9cac-b02723b8db8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Click this link to enter your account details to claim the lottery www.google.com\"\n",
        ")\n",
        "\n",
        "print(classify_review(text_2, model, tokenizer, device, max_length=train_dataset.max_length))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mYnX-gI1CfQY",
      "metadata": {
        "id": "mYnX-gI1CfQY"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"spam_classifier.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "vEJNK0piom2s",
      "metadata": {
        "id": "vEJNK0piom2s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
      "metadata": {
        "id": "cc4e68a5-d492-493b-87ef-45c475f353f5"
      },
      "outputs": [],
      "source": [
        "model_state_dict = torch.load(\"spam_classifier.pth\")\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6BzS-WMsK9GL",
      "metadata": {
        "id": "6BzS-WMsK9GL"
      },
      "outputs": [],
      "source": [
        "t1=pd.read_excel('/content/scams12.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5M36i3R8Nl0X",
      "metadata": {
        "id": "5M36i3R8Nl0X"
      },
      "outputs": [],
      "source": [
        "text=t1['content']\n",
        "label=t1['is scam']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WYDhDPDkOC8d",
      "metadata": {
        "id": "WYDhDPDkOC8d"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DVhM3V7TNi3X",
      "metadata": {
        "id": "DVhM3V7TNi3X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b997053-fd5e-4a57-b792-8f8fbc53ad51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Positive Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Positive Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Positive Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "Negative Positive\n",
            "Negative Negative\n",
            "0.5418250950570342\n"
          ]
        }
      ],
      "source": [
        "c=0\n",
        "c1=0\n",
        "for i in range(len(t1)):\n",
        "  st=classify_review(text[i], model, tokenizer, device, max_length=train_dataset.max_length)\n",
        "  pr='Negative' if label[i]==0 else'Positive'\n",
        "  print(st,pr)\n",
        "  if st=='Negative':\n",
        "    c1=c1+1\n",
        "  if st==pr:\n",
        "    c=c+1\n",
        "print(c/len(t1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lXgrM-8WOKJa",
      "metadata": {
        "id": "lXgrM-8WOKJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "304d9fe0-cb53-4e5c-ffba-84abc610b944"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "448\n"
          ]
        }
      ],
      "source": [
        "print(c1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "NfD96hUNoam_",
      "metadata": {
        "id": "NfD96hUNoam_"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "QJREnDeMX1fi",
      "metadata": {
        "id": "QJREnDeMX1fi"
      },
      "outputs": [],
      "source": [
        "pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3nwpIrtZSTr5",
      "metadata": {
        "id": "3nwpIrtZSTr5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from tokenizers import Encoding\n",
        "\n",
        "# Load fine-tuned GPT-2 model\n",
        "model_path = \"/content/spam_classifier.pth\"\n",
        "model.load_state_dict(torch.load(model_path))\n",
        "model = model.to(\"cpu\")\n",
        "\n",
        "\n",
        "# Prepare sample input\n",
        "text = \"Hey enter your account details to claim the prize\"\n",
        "inputs = tokenizer.encode(text)\n",
        "\n",
        "# Convert Encoding to tensor input\n",
        "input_ids = torch.tensor(inputs).unsqueeze(0).cpu()\n",
        "\n",
        "# Export to ONNX\n",
        "torch.onnx.export(model, input_ids, \"modelgpt.onnx\", opset_version=12, verbose=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebRJXygLW88e",
      "metadata": {
        "id": "ebRJXygLW88e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to your ONNX file\n",
        "onnx_file_path = \"modelgpt.onnx\"  # Replace with the path to your ONNX file\n",
        "\n",
        "# Get the size of the ONNX file\n",
        "onnx_file_size = os.path.getsize(onnx_file_path)\n",
        "\n",
        "print(\"Size of the ONNX file:\", onnx_file_size, \"bytes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J0BNSn2uYKgq",
      "metadata": {
        "id": "J0BNSn2uYKgq"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Path to your ONNX file\n",
        "onnx_file_path = \"/content/spam_classifier.pth\"  # Replace with the path to your ONNX file\n",
        "\n",
        "# Get the size of the ONNX file\n",
        "onnx_file_size = os.path.getsize(onnx_file_path)\n",
        "\n",
        "print(\"Size of the ONNX file:\", onnx_file_size, \"bytes\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f667679113a9478db7243f311608e899": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64a9ac4675f0427a9b50d0aa238a36ce",
              "IPY_MODEL_9fb76f37cc54483eabb6cdee5ca86149",
              "IPY_MODEL_7a72cbd2222744c3aa8a25c54b811bd5"
            ],
            "layout": "IPY_MODEL_2655f9d09dc743609a0b8314884a072c"
          }
        },
        "64a9ac4675f0427a9b50d0aa238a36ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0881cffe64bb43a4b50f35e9f7692b11",
            "placeholder": "​",
            "style": "IPY_MODEL_b8b7e980ce504205b70175f5fe36cc5e",
            "value": "model.safetensors: 100%"
          }
        },
        "9fb76f37cc54483eabb6cdee5ca86149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd1ab6864754d778f76e6fa3409310e",
            "max": 352824413,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_832fb971254e49c7b0670b7ed7efdfa0",
            "value": 352824413
          }
        },
        "7a72cbd2222744c3aa8a25c54b811bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2cb10b3e007406687ef78820ea8b2a1",
            "placeholder": "​",
            "style": "IPY_MODEL_bf01ae97a5b74b0785144e87b82a4375",
            "value": " 353M/353M [00:05&lt;00:00, 232MB/s]"
          }
        },
        "2655f9d09dc743609a0b8314884a072c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0881cffe64bb43a4b50f35e9f7692b11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8b7e980ce504205b70175f5fe36cc5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dd1ab6864754d778f76e6fa3409310e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "832fb971254e49c7b0670b7ed7efdfa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e2cb10b3e007406687ef78820ea8b2a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf01ae97a5b74b0785144e87b82a4375": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}